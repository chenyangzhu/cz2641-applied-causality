{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SC(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, N, P, T):\n",
    "    \"\"\"\n",
    "    h: p x 1\n",
    "    L: N x T\n",
    "    delta: T x 1\n",
    "    gamma: N x 1\n",
    "    \"\"\"\n",
    "    super(SC, self).__init__()\n",
    "    \n",
    "    self.h = torch.rand(P, 1, requires_grad=True, dtype=torch.double)\n",
    "    self.L = torch.rand(N, T, requires_grad=True, dtype=torch.double)\n",
    "    self.delta = torch.rand(T, 1, requires_grad=True, dtype=torch.double)\n",
    "    self.gamma = torch.rand(N, 1, requires_grad=True, dtype=torch.double)\n",
    "    \n",
    "    self.N = N\n",
    "    self.P = P\n",
    "    self.T = T\n",
    "    \n",
    "    self.lambda_L = 0.1\n",
    "    self.lambda_h = 0.9\n",
    "        \n",
    "  def forward(self, X, Y):\n",
    "    \"\"\"\n",
    "    X: N x P\n",
    "    \"\"\"\n",
    "    \n",
    "    Xh = torch.matmul(X, self.h)  # N x 1\n",
    "    gamma1 = torch.matmul(self.gamma, torch.ones(1, self.T, dtype=torch.double)) # N x T\n",
    "    delta1 = torch.matmul(torch.ones(self.N, 1, dtype=torch.double), self.delta.T)\n",
    "    \n",
    "    loss = torch.norm(Y - self.L - Xh - gamma1 - delta1, 2) / (self.N * self.T)\n",
    "    \n",
    "    loss_penalty = loss + self.lambda_L * torch.norm(self.L, 'nuc') + self.lambda_h * torch.sum(torch.abs(self.h))    \n",
    "\n",
    "    return loss_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "P = 10\n",
    "T = 100\n",
    "\n",
    "X = torch.ones(N, P)\n",
    "Y = torch.ones(N, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SC(N, P, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([model.h, model.L, model.delta, model.gamma],\n",
    "                            lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10000):\n",
    "  optimizer.zero_grad()\n",
    "  loss = model.forward(X+1, Y)\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.1445e-03,  3.2464e-05,  3.2493e-05,  ...,  3.2471e-05,\n",
       "          3.2464e-05,  3.2598e-05],\n",
       "        [ 3.2501e-05, -5.1444e-03,  3.2492e-05,  ...,  3.2579e-05,\n",
       "          3.2556e-05,  3.2560e-05],\n",
       "        [ 3.2497e-05,  3.2555e-05, -5.1442e-03,  ...,  3.2544e-05,\n",
       "          3.2513e-05,  3.2610e-05],\n",
       "        ...,\n",
       "        [-1.5553e-06, -1.5721e-06, -1.5653e-06,  ..., -1.5649e-06,\n",
       "         -1.5641e-06, -1.5676e-06],\n",
       "        [-1.5553e-06, -1.5721e-06, -1.5653e-06,  ..., -1.5649e-06,\n",
       "         -1.5641e-06, -1.5676e-06],\n",
       "        [-1.5553e-06, -1.5721e-06, -1.5653e-06,  ..., -1.5649e-06,\n",
       "         -1.5641e-06, -1.5676e-06]], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. True Data (using categorical variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"../data/synthetic_matrix.csv\")\n",
    "X = pd.read_csv(\"../data/objects_c.csv\")\n",
    "X = X[['id', 'category_code']]\n",
    "large = Y.merge(X, left_on='id', right_on='id', how='left')\n",
    "\n",
    "Y = large.iloc[:, 3:7]\n",
    "X = large.iloc[:, -1]\n",
    "X = X.fillna(\"others\")\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "X = enc.fit_transform(X.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T = Y.shape\n",
    "_, P = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = torch.tensor(X).double()\n",
    "Y_t = torch.tensor(Y.to_numpy()).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Run Synthetic Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SC(N, P, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([model.h, model.L, model.delta, model.gamma],\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat mask\n",
    "mask = pd.read_csv(\"../data/mask.csv\", index_col=0).to_numpy()\n",
    "Y_t = torch.multiply(Y_t, torch.tensor(mask, dtype=torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5000):\n",
    "  optimizer.zero_grad()\n",
    "  loss = model.forward(X_t, Y_t)\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.8279e-06, 8.4453e-05, 1.7894e-05, 1.3478e-04],\n",
       "        [6.1287e-05, 6.6939e-05, 4.5202e-05, 9.8462e-05],\n",
       "        [9.7789e-05, 1.0659e-04, 5.6394e-05, 3.6790e-05],\n",
       "        ...,\n",
       "        [1.0546e-04, 3.2982e-05, 7.0968e-05, 2.1370e-05],\n",
       "        [7.5191e-05, 8.6478e-05, 4.9721e-05, 5.9432e-05],\n",
       "        [2.7941e-05, 1.1285e-04, 4.2290e-05, 4.9242e-05]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/L1.csv', model.L.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"../data/synthetic_matrix.csv\")\n",
    "X = pd.read_csv(\"../data/objects_c.csv\")\n",
    "X = X[['id', 'category_code']]\n",
    "large = Y.merge(X, left_on='id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = large[large.funding_round_num.isna()] # Select Control group only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyangzhu/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:395: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  check_array(X, dtype=np.int)\n",
      "/Users/chenyangzhu/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "/Users/chenyangzhu/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "Y = large.iloc[:, 3:7]\n",
    "X = large.iloc[:, -1]\n",
    "X = X.fillna(\"others\")\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "X = enc.fit_transform(X.to_numpy().reshape(-1,1))\n",
    "\n",
    "N, T = Y.shape\n",
    "_, P = X.shape\n",
    "\n",
    "X_t = torch.tensor(X).double()\n",
    "Y_t = torch.tensor(Y.to_numpy()).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.5582, 0.8230, 0.7878], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3747, 0.6204, 0.3241, 0.3811], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5146, 0.6359, 0.1511, 0.1947], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5494, 0.7543, 0.2384, 0.2103], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0484, 0.1279, 0.0487, 0.1831], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2919, 0.4936, 0.2587, 0.7468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2171, 0.4892, 0.6178, 0.7024], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3824, 0.8358, 0.3283, 0.6140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5848, 0.5371, 0.1358, 0.1820], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3463, 0.4914, 0.7765, 0.1131], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7216, 0.8659, 0.4764, 0.8152], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7465, 0.1250, 0.6311, 0.5380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8910, 0.6975, 0.8521, 0.6277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6226, 0.1474, 0.7905, 0.1266], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6206, 0.1663, 0.0578, 0.0655], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7115, 0.3301, 0.2937, 0.3406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5827, 0.5029, 0.1423, 0.2460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4468, 0.6488, 0.7172, 0.2879], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2371, 0.6085, 0.7650, 0.6108], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1544, 0.2219, 0.7621, 0.6856], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4341, 0.0951, 0.5260, 0.1273], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4956, 0.5403, 0.6312, 0.1251], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3898, 0.3643, 0.4159, 0.5850], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1044, 0.7611, 0.3547, 0.5646], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5417, 0.1334, 0.2761, 0.3234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1463, 0.7607, 0.4337, 0.0866], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4954, 0.3459, 0.8272, 0.7910], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6427, 0.6214, 0.5013, 0.4092], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7620, 0.6201, 0.8062, 0.3741], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8539, 0.7069, 0.7276, 0.6312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3653, 0.5787, 0.3907, 0.6571], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0567, 0.2104, 0.0335, 0.1185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2748, 0.7085, 0.0958, 0.4857], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1584, 0.2466, 0.1067, 0.6186], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5003, 0.7350, 0.1078, 0.2370], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0712, 0.1043, 0.0335, 0.2936], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0499, 0.0413, 0.1378, 0.3193], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2949, 0.3049, 0.6604, 0.1201], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2443, 0.5895, 0.3760, 0.2981], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4298, 0.2705, 0.3129, 0.2029], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4461, 0.6448, 0.1265, 0.1267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0577, 0.5508, 0.1321, 0.0584], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6216, 0.8108, 0.3940, 0.6851], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1288, 0.4059, 0.2073, 0.1162], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7702, 0.6524, 0.1680, 0.4344], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5782, 0.1020, 0.1104, 0.6736], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7956, 0.7126, 0.7404, 0.7043], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4168, 0.4141, 0.2715, 0.1970], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3073, 0.5477, 0.6568, 0.6006], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4235, 0.8313, 0.4910, 0.1618], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8239, 0.7235, 0.6169, 0.2886], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7542, 0.4984, 0.2263, 0.3900], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2133, 0.2239, 0.5283, 0.4956], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7400, 0.2748, 0.4819, 0.3480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2524, 0.1127, 0.3417, 0.6390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6270, 0.8068, 0.8233, 0.2535], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5586, 0.1071, 0.6852, 0.0881], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1911, 0.0835, 0.0395, 0.4141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5494, 0.0991, 0.6415, 0.5759], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7446, 0.4510, 0.5515, 0.1588], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3777, 0.7674, 0.2127, 0.2564], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6221, 0.7322, 0.1099, 0.3855], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2356, 0.6589, 0.1263, 0.7632], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4517, 0.7790, 0.1321, 0.3002], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1136, 0.1294, 0.1283, 0.5725], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2864, 0.7672, 0.1953, 0.3033], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7042, 0.2926, 0.6046, 0.7119], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8761, 0.6305, 0.8339, 0.6953], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1959, 0.3520, 0.2808, 0.7090], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2264, 0.7180, 0.4008, 0.4848], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8071, 0.6688, 0.4240, 0.7436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5446, 0.1746, 0.1075, 0.4585], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1391, 0.0737, 0.0483, 0.4259], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2440, 0.1075, 0.7124, 0.2331], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2069, 0.0532, 0.2823, 0.0536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1588, 0.3482, 0.5183, 0.2877], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7202, 0.0772, 0.0949, 0.5992], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3813, 0.6810, 0.4510, 0.3516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5370, 0.6026, 0.3836, 0.2938], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7463, 0.1446, 0.3373, 0.6822], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4931, 0.7671, 0.3897, 0.7706], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1488, 0.3730, 0.4690, 0.4849], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2891, 0.4870, 0.2315, 0.3610], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2945, 0.3709, 0.5187, 0.6440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2115, 0.4412, 0.1528, 0.3097], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1346, 0.4678, 0.3514, 0.7219], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4009, 0.4440, 0.6964, 0.2522], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6393, 0.5339, 0.8658, 0.4739], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2353, 0.1814, 0.6460, 0.6653], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6902, 0.7655, 0.8235, 0.6536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6474, 0.5222, 0.4136, 0.7393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5582, 0.5031, 0.1902, 0.6033], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1868, 0.8205, 0.8214, 0.7770], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5596, 0.1234, 0.8259, 0.3839], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1165, 0.1327, 0.4440, 0.4364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3461, 0.6871, 0.3004, 0.2449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1397, 0.8011, 0.1720, 0.7234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4214, 0.5402, 0.8592, 0.6310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6173, 0.4031, 0.6478, 0.2241], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3557, 0.7751, 0.3110, 0.3611], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4651, 0.1133, 0.7370, 0.3607], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6634, 0.4762, 0.2188, 0.5042], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3447, 0.7740, 0.5660, 0.7145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6035, 0.3629, 0.6752, 0.3169], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7975, 0.5126, 0.6717, 0.3160], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1982, 0.7859, 0.1322, 0.8194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3024, 0.4311, 0.2200, 0.1087], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7456, 0.7766, 0.4746, 0.3541], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4692, 0.8427, 0.3171, 0.4341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8332, 0.6606, 0.1570, 0.4397], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3686, 0.3341, 0.2515, 0.1961], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5866, 0.4206, 0.1672, 0.3393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2789, 0.8049, 0.1282, 0.3265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3826, 0.8050, 0.4963, 0.8650], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3674, 0.1064, 0.5643, 0.2250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3076, 0.4111, 0.4970, 0.4352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5716, 0.2561, 0.2446, 0.1606], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6549, 0.5752, 0.6966, 0.1245], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1434, 0.3289, 0.8033, 0.2381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6840, 0.3889, 0.6455, 0.4128], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0610, 0.1402, 0.1196, 0.4344], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6786, 0.2759, 0.7719, 0.8647], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8399, 0.4591, 0.2668, 0.5998], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4821, 0.4338, 0.7718, 0.1860], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5638, 0.6122, 0.2604, 0.2260], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4031, 0.1186, 0.0781, 0.3118], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8316, 0.6654, 0.1728, 0.2047], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5687, 0.1844, 0.2802, 0.2297], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4273, 0.4034, 0.1842, 0.6640], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2791, 0.2315, 0.7039, 0.2782], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0889, 0.6236, 0.5264, 0.2655], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2859, 0.6631, 0.1724, 0.8043], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1370, 0.7785, 0.6167, 0.1888], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4086, 0.2846, 0.7664, 0.7393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7843, 0.3704, 0.1953, 0.7023], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3228, 0.7665, 0.6596, 0.8298], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2611, 0.1968, 0.7636, 0.3838], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1564, 0.7838, 0.1488, 0.4666], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1737, 0.7833, 0.2211, 0.1449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2271, 0.7375, 0.4311, 0.6780], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3394, 0.2451, 0.3113, 0.1521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7350, 0.8172, 0.7468, 0.1285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3296, 0.2751, 0.7295, 0.7083], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0789, 0.5832, 0.4021, 0.2842], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3148, 0.1360, 0.5408, 0.5166], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1121, 0.7516, 0.6536, 0.5076], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6157, 0.5563, 0.7446, 0.5717], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3408, 0.6487, 0.7798, 0.5793], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3863, 0.2784, 0.5635, 0.6384], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7138, 0.4960, 0.5429, 0.5859], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3828, 0.2945, 0.6098, 0.7068], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7090, 0.2337, 0.2723, 0.1943], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1067, 0.3928, 0.0739, 0.2450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4153, 0.4394, 0.3259, 0.4530], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6250, 0.4916, 0.8231, 0.3628], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6799, 0.6497, 0.1668, 0.2616], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3912, 0.1382, 0.4250, 0.4236], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4529, 0.0637, 0.2999, 0.0809], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6024, 0.3130, 0.7995, 0.7036], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7349, 0.4305, 0.1600, 0.3311], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1832, 0.3773, 0.3365, 0.4694], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7434, 0.6067, 0.6280, 0.6174], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6200, 0.3259, 0.1135, 0.5154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5970, 0.6802, 0.4757, 0.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0995, 0.0994, 0.1630, 0.4812], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3069, 0.0784, 0.0706, 0.4805], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4896, 0.8018, 0.0914, 0.2854], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2869, 0.4884, 0.4958, 0.1798], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4263, 0.0819, 0.2122, 0.2452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2685, 0.5011, 0.2376, 0.5115], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5361, 0.0752, 0.1710, 0.4978], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7646, 0.7086, 0.4512, 0.6770], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7897, 0.6762, 0.7014, 0.4043], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3032, 0.1459, 0.1101, 0.6314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5530, 0.7232, 0.1577, 0.2351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7584, 0.5482, 0.8449, 0.3975], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3645, 0.5442, 0.7086, 0.1823], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8251, 0.3504, 0.7748, 0.2686], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5657, 0.8360, 0.4650, 0.1408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3653, 0.3743, 0.0907, 0.4967], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1991, 0.5080, 0.6884, 0.7882], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3374, 0.3848, 0.2091, 0.5899], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2574, 0.7310, 0.2837, 0.4446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6720, 0.4129, 0.5391, 0.7590], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2105, 0.6130, 0.6505, 0.5792], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7999, 0.3065, 0.1888, 0.5755], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6219, 0.3663, 0.5271, 0.3991], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7332, 0.4678, 0.1840, 0.1365], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3924, 0.6950, 0.4061, 0.2458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7523, 0.3365, 0.3663, 0.6923], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2467, 0.5770, 0.7911, 0.1982], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2142, 0.2133, 0.3523, 0.7929], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1404, 0.4231, 0.4414, 0.7392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5063, 0.6242, 0.3849, 0.6328], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6050, 0.7976, 0.2280, 0.7200], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4022, 0.3446, 0.6339, 0.1056], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3704, 0.6524, 0.7883, 0.3733], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6027, 0.2360, 0.2997, 0.5244], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5850, 0.7672, 0.5421, 0.5780], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7457, 0.2921, 0.2679, 0.2801], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4563, 0.5586, 0.5896, 0.7872], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7507, 0.6148, 0.6905, 0.3668], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4917, 0.6335, 0.5316, 0.7618], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8392, 0.7748, 0.6853, 0.8521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6389, 0.7084, 0.8068, 0.6075], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4468, 0.2677, 0.3968, 0.0730], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4480, 0.6980, 0.5455, 0.5689], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1721, 0.3572, 0.0788, 0.7915], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6103, 0.0881, 0.2633, 0.5716], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3916, 0.1999, 0.2872, 0.0864], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7954, 0.6763, 0.4296, 0.5241], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2347, 0.1796, 0.4443, 0.3377], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3264, 0.5523, 0.4147, 0.6141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4046, 0.7694, 0.3827, 0.5875], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4852, 0.1471, 0.8035, 0.2971], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5670, 0.2589, 0.6639, 0.7921], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1237, 0.7732, 0.1204, 0.3198], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8605, 0.4149, 0.4967, 0.8285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7379, 0.4080, 0.4095, 0.5907], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1420, 0.6925, 0.8049, 0.2125], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0824, 0.3293, 0.3875, 0.6696], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2184, 0.6407, 0.0850, 0.6481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8898, 0.8810, 0.8965, 0.7299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7240, 0.2438, 0.5589, 0.6611], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4317, 0.4412, 0.4303, 0.2983], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2037, 0.3227, 0.8098, 0.2245], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5960, 0.3476, 0.4511, 0.4077], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5592, 0.0961, 0.2873, 0.3922], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4168, 0.6826, 0.3933, 0.2198], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2671, 0.8243, 0.7587, 0.3278], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1870, 0.2912, 0.5332, 0.5910], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1394, 0.3148, 0.7731, 0.3313], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6103, 0.7848, 0.6544, 0.5893], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7966, 0.1664, 0.3853, 0.4791], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8058, 0.8320, 0.1323, 0.5902], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7817, 0.3101, 0.2209, 0.3759], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5743, 0.1552, 0.7596, 0.3174], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7708, 0.7779, 0.2357, 0.7643], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2458, 0.4781, 0.1695, 0.2153], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4045, 0.7940, 0.1709, 0.1599], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5178, 0.1103, 0.1867, 0.6874], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2256, 0.7585, 0.2912, 0.1105], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3915, 0.2550, 0.1478, 0.6636], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1909, 0.1102, 0.0984, 0.5922], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1814, 0.3366, 0.5847, 0.1583], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7001, 0.3316, 0.5874, 0.5250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5610, 0.7532, 0.2558, 0.0949], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0721, 0.1188, 0.0372, 0.3113], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6938, 0.2156, 0.1399, 0.2823], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2837, 0.2314, 0.0787, 0.7120], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6571, 0.0748, 0.1775, 0.4295], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8472, 0.6147, 0.8087, 0.1935], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2683, 0.5026, 0.5255, 0.4369], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4847, 0.3519, 0.8109, 0.7653], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6853, 0.1021, 0.3920, 0.6610], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7105, 0.8295, 0.5910, 0.8086], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7146, 0.8321, 0.5979, 0.8042], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7058, 0.3413, 0.3169, 0.6577], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5620, 0.3026, 0.0954, 0.7349], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1251, 0.0972, 0.6628, 0.3465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8377, 0.3746, 0.6143, 0.7814], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8706, 0.7640, 0.4487, 0.7495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5613, 0.2887, 0.1114, 0.8120], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1017, 0.7935, 0.1538, 0.5506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7289, 0.5633, 0.2811, 0.6518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1352, 0.5477, 0.0872, 0.5920], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4370, 0.2240, 0.5380, 0.2756], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7515, 0.3558, 0.8272, 0.6884], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3409, 0.4143, 0.3125, 0.1652], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6887, 0.3890, 0.6900, 0.8399], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3490, 0.5968, 0.1693, 0.7298], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2846, 0.6569, 0.5460, 0.3247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4011, 0.6446, 0.5026, 0.1868], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6038, 0.1191, 0.1006, 0.7415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1006, 0.0828, 0.2406, 0.3343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8133, 0.4433, 0.7323, 0.2844], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3733, 0.7551, 0.2845, 0.2752], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4716, 0.5941, 0.1258, 0.2862], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8242, 0.7140, 0.8428, 0.4388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1466, 0.3053, 0.5385, 0.3826], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4978, 0.2949, 0.7268, 0.7944], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7277, 0.3280, 0.8202, 0.7053], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4598, 0.1955, 0.7462, 0.2540], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4378, 0.3266, 0.5430, 0.5095], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3737, 0.2489, 0.6792, 0.7816], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6031, 0.2379, 0.1055, 0.2024], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5767, 0.3080, 0.2721, 0.3995], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0879, 0.0815, 0.4638, 0.0604], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8191, 0.3695, 0.7992, 0.5215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7929, 0.3120, 0.8577, 0.7330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1554, 0.6823, 0.5756, 0.1156], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2725, 0.5225, 0.1225, 0.1564], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2758, 0.4760, 0.5603, 0.6943], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4531, 0.4358, 0.4003, 0.4858], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7176, 0.3290, 0.3579, 0.3579], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5782, 0.8224, 0.5262, 0.2001], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2609, 0.8374, 0.5780, 0.3895], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5090, 0.4511, 0.3336, 0.7853], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2277, 0.4097, 0.2960, 0.6432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2433, 0.4906, 0.3091, 0.5283], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8763, 0.7991, 0.4438, 0.8536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4213, 0.0989, 0.3343, 0.4166], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6821, 0.2056, 0.3824, 0.1648], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6566, 0.7477, 0.3924, 0.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6911, 0.4655, 0.1224, 0.3167], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6139, 0.4891, 0.4819, 0.7040], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1318, 0.8032, 0.1625, 0.4707], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5193, 0.2301, 0.8415, 0.6270], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4477, 0.8463, 0.7188, 0.6838], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3257, 0.1831, 0.7188, 0.7768], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3186, 0.5814, 0.5356, 0.1562], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1415, 0.6599, 0.1012, 0.3557], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7842, 0.1005, 0.5257, 0.5041], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5883, 0.3599, 0.4264, 0.2950], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4320, 0.7343, 0.6701, 0.4985], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8396, 0.6741, 0.8763, 0.8138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2069, 0.4796, 0.2607, 0.5088], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6277, 0.6739, 0.2147, 0.3216], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6087, 0.1064, 0.5461, 0.4037], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2581, 0.5620, 0.7399, 0.6654], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7097, 0.1365, 0.8369, 0.2957], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8242, 0.2639, 0.7036, 0.8578], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1646, 0.0570, 0.1488, 0.3536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1973, 0.5186, 0.6500, 0.2046], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8530, 0.8231, 0.6194, 0.7124], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5654, 0.1582, 0.4638, 0.4982], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3448, 0.6390, 0.1237, 0.5576], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0495, 0.2455, 0.0516, 0.3153], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4161, 0.2213, 0.8066, 0.5669], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2991, 0.2399, 0.2180, 0.5346], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5854, 0.4316, 0.2490, 0.2256], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3683, 0.5458, 0.1796, 0.6810], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3289, 0.0817, 0.3939, 0.5920], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7334, 0.6857, 0.1204, 0.4703], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7209, 0.1049, 0.1787, 0.4185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3794, 0.7121, 0.7226, 0.5138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5811, 0.4895, 0.4192, 0.7351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5979, 0.2871, 0.4925, 0.3956], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1050, 0.7788, 0.3840, 0.5860], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4022, 0.3042, 0.4893, 0.5435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1175, 0.2327, 0.2999, 0.3511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3208, 0.1636, 0.1133, 0.4592], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4015, 0.8255, 0.6979, 0.7606], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8710, 0.3201, 0.8587, 0.8787], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7291, 0.4640, 0.8165, 0.3466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6451, 0.4207, 0.6128, 0.2266], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3508, 0.1007, 0.2778, 0.4383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1708, 0.1168, 0.3967, 0.1957], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3955, 0.4198, 0.3656, 0.1802], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4924, 0.0608, 0.0889, 0.3463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5142, 0.4436, 0.5647, 0.6521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1734, 0.6310, 0.6798, 0.7045], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1102, 0.5795, 0.1003, 0.7021], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1663, 0.7282, 0.7963, 0.6206], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8369, 0.7809, 0.7810, 0.7910], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4738, 0.3667, 0.1807, 0.2727], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5973, 0.3406, 0.6731, 0.6081], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1323, 0.2958, 0.8123, 0.4421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1525, 0.5120, 0.4749, 0.1644], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4372, 0.3607, 0.6676, 0.2187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7127, 0.1940, 0.5120, 0.7850], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4049, 0.4864, 0.6167, 0.4341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5142, 0.3345, 0.7165, 0.3102], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4575, 0.4744, 0.1831, 0.2732], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1854, 0.5429, 0.1196, 0.1188], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3646, 0.4157, 0.4816, 0.2653], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1224, 0.2209, 0.5081, 0.3428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6672, 0.7716, 0.6166, 0.7913], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2947, 0.2297, 0.3990, 0.2257], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3715, 0.0878, 0.6198, 0.0797], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3272, 0.3647, 0.0694, 0.1870], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6736, 0.1664, 0.1512, 0.4515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2062, 0.4714, 0.6112, 0.1086], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6057, 0.3995, 0.1172, 0.3772], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0896, 0.5850, 0.2067, 0.3194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8593, 0.7282, 0.7271, 0.1338], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3396, 0.7910, 0.3543, 0.5441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4964, 0.1193, 0.2292, 0.4487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6016, 0.8087, 0.6492, 0.3946], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6248, 0.1941, 0.3673, 0.5120], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4533, 0.3474, 0.6972, 0.3017], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7940, 0.3186, 0.8206, 0.3194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8209, 0.6869, 0.1828, 0.5445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7815, 0.4187, 0.7147, 0.3583], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3651, 0.6555, 0.3874, 0.8101], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8044, 0.1064, 0.3572, 0.2086], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5117, 0.8318, 0.7073, 0.8633], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2514, 0.3859, 0.3398, 0.2042], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4231, 0.2351, 0.2827, 0.0741], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0715, 0.1721, 0.5474, 0.0714], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4533, 0.7002, 0.1415, 0.7577], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2794, 0.1084, 0.0938, 0.2090], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4470, 0.2976, 0.1438, 0.1123], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6367, 0.6085, 0.3554, 0.2890], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4653, 0.3666, 0.1529, 0.6862], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3120, 0.8078, 0.5988, 0.2908], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4646, 0.5783, 0.4474, 0.6481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1781, 0.1022, 0.0945, 0.2288], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6183, 0.5796, 0.8528, 0.8122], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8301, 0.6849, 0.5111, 0.5977], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8475, 0.7609, 0.3050, 0.4607], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3959, 0.6201, 0.4955, 0.6775], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3178, 0.0996, 0.3689, 0.7185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7280, 0.2551, 0.3105, 0.6171], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6688, 0.1242, 0.5466, 0.4767], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4616, 0.0903, 0.3987, 0.6036], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8072, 0.3807, 0.3290, 0.1780], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4637, 0.1733, 0.4655, 0.2802], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6910, 0.8557, 0.2200, 0.6790], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1443, 0.6341, 0.5285, 0.4105], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7969, 0.6101, 0.2707, 0.5270], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2233, 0.7854, 0.1025, 0.3500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1526, 0.5683, 0.7770, 0.4173], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2951, 0.2419, 0.7176, 0.4882], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2033, 0.8154, 0.2663, 0.3944], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3762, 0.1697, 0.0887, 0.3110], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4784, 0.3260, 0.5447, 0.4746], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3056, 0.7221, 0.0965, 0.2551], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1489, 0.3518, 0.7604, 0.7761], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2250, 0.2212, 0.2051, 0.8002], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2767, 0.1455, 0.1771, 0.7075], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6307, 0.2251, 0.4571, 0.6893], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4656, 0.7252, 0.3947, 0.7956], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0920, 0.4607, 0.4053, 0.0737], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3513, 0.8107, 0.2408, 0.3868], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5984, 0.6683, 0.7515, 0.2149], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4197, 0.2483, 0.4405, 0.3652], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3152, 0.8348, 0.4912, 0.6867], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6069, 0.3772, 0.5652, 0.1410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6477, 0.5877, 0.3956, 0.8089], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4179, 0.2590, 0.4708, 0.7685], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5756, 0.3933, 0.4679, 0.1898], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2380, 0.5583, 0.6762, 0.7813], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3987, 0.4349, 0.2290, 0.8237], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2616, 0.4582, 0.6936, 0.1853], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7569, 0.1625, 0.8114, 0.2467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1918, 0.4235, 0.4975, 0.3498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8548, 0.5308, 0.4234, 0.7771], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7936, 0.8531, 0.2847, 0.7051], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6153, 0.4194, 0.5781, 0.1697], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6406, 0.7516, 0.1686, 0.7813], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3554, 0.2469, 0.0987, 0.3726], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6491, 0.4372, 0.4871, 0.5791], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7296, 0.8377, 0.6316, 0.4209], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7940, 0.7574, 0.8309, 0.2105], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3774, 0.7386, 0.1142, 0.3606], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2531, 0.2575, 0.7754, 0.4922], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7365, 0.6798, 0.1275, 0.5978], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6838, 0.6804, 0.6713, 0.8039], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1388, 0.2606, 0.1208, 0.3898], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3901, 0.2229, 0.1694, 0.0543], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5225, 0.6871, 0.4993, 0.4357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6560, 0.2788, 0.2953, 0.7537], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4833, 0.4076, 0.3122, 0.2011], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6674, 0.0714, 0.0706, 0.1567], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0894, 0.1810, 0.6159, 0.4242], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0672, 0.2056, 0.4772, 0.4399], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2836, 0.8292, 0.1391, 0.8356], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1150, 0.3413, 0.0368, 0.1286], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6021, 0.5215, 0.1425, 0.0985], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7520, 0.3792, 0.2767, 0.7135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1475, 0.5313, 0.2695, 0.1409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3547, 0.2925, 0.7688, 0.5876], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3840, 0.8217, 0.6541, 0.8577], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8170, 0.4237, 0.4208, 0.5260], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7413, 0.6528, 0.3140, 0.3838], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5299, 0.1091, 0.1857, 0.6786], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4885, 0.6730, 0.2543, 0.7028], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2037, 0.3033, 0.3552, 0.4222], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4136, 0.6598, 0.5395, 0.3986], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1427, 0.4409, 0.4297, 0.2355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5590, 0.8304, 0.4246, 0.7072], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3639, 0.4995, 0.1541, 0.4192], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2524, 0.4848, 0.3873, 0.1675], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4351, 0.1714, 0.7513, 0.7075], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2832, 0.1596, 0.8231, 0.7433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3222, 0.0885, 0.7065, 0.1655], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2265, 0.1110, 0.3498, 0.3131], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5735, 0.3740, 0.2367, 0.1204], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3943, 0.7421, 0.3154, 0.5175], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6584, 0.3380, 0.1199, 0.6747], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8065, 0.4126, 0.5460, 0.5335], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7886, 0.4959, 0.8179, 0.6129], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4959, 0.7206, 0.4221, 0.3438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8295, 0.4280, 0.8821, 0.8733], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5909, 0.6321, 0.6003, 0.3059], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2035, 0.2211, 0.2549, 0.6606], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5416, 0.2150, 0.2738, 0.7264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6899, 0.6796, 0.1839, 0.6543], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4712, 0.2939, 0.4271, 0.3623], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2067, 0.2067, 0.2082, 0.3921], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4207, 0.4585, 0.5348, 0.1609], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2631, 0.4390, 0.5421, 0.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3766, 0.3359, 0.2071, 0.2936], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4516, 0.3641, 0.4387, 0.8146], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4871, 0.4079, 0.5421, 0.8319], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5876, 0.3130, 0.8019, 0.1207], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5766, 0.1840, 0.1303, 0.4838], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2615, 0.5504, 0.5510, 0.5469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8673, 0.9024, 0.9131, 0.9085], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3329, 0.5008, 0.3225, 0.1159], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7302, 0.4576, 0.5188, 0.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1239, 0.7050, 0.0865, 0.2112], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2357, 0.8003, 0.4728, 0.3351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6955, 0.8653, 0.7940, 0.7215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0762, 0.1053, 0.0921, 0.3454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5521, 0.6392, 0.8107, 0.1187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3217, 0.2109, 0.3950, 0.2567], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6058, 0.6857, 0.7993, 0.4861], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8073, 0.4927, 0.4360, 0.7148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6276, 0.5372, 0.6692, 0.1631], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3053, 0.7504, 0.7964, 0.4807], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8545, 0.4785, 0.6300, 0.3695], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4431, 0.3863, 0.3854, 0.7077], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4505, 0.1898, 0.3153, 0.3618], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3700, 0.4788, 0.5652, 0.4916], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3411, 0.1821, 0.6729, 0.6449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1156, 0.1754, 0.4389, 0.5850], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1559, 0.4922, 0.0747, 0.4853], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4537, 0.1136, 0.8233, 0.7735], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6470, 0.2100, 0.8264, 0.7887], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5635, 0.5912, 0.7755, 0.3785], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1503, 0.8185, 0.6496, 0.2701], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2364, 0.6164, 0.7725, 0.3972], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2813, 0.4924, 0.6660, 0.1059], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1071, 0.1458, 0.0539, 0.0746], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3656, 0.1684, 0.0791, 0.3234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1286, 0.1900, 0.6865, 0.0673], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0636, 0.6112, 0.2062, 0.0925], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5151, 0.3374, 0.2443, 0.0700], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5507, 0.8161, 0.3909, 0.1126], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2281, 0.7676, 0.2146, 0.3487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8192, 0.8391, 0.3250, 0.4098], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5926, 0.3281, 0.1230, 0.5299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6925, 0.0864, 0.2461, 0.2406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2277, 0.1354, 0.7672, 0.3367], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1902, 0.5404, 0.1742, 0.7815], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2409, 0.8076, 0.5927, 0.6291], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5472, 0.2135, 0.3314, 0.2880], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2329, 0.7603, 0.2668, 0.6130], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4525, 0.6441, 0.5505, 0.6770], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3476, 0.2358, 0.1366, 0.4363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8523, 0.6659, 0.8083, 0.7851], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6736, 0.6976, 0.4498, 0.5517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3314, 0.4946, 0.2846, 0.2129], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4854, 0.7249, 0.2327, 0.3988], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7596, 0.2251, 0.3940, 0.4959], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5359, 0.1798, 0.4627, 0.4850], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3772, 0.6986, 0.3729, 0.5735], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1055, 0.2517, 0.7100, 0.2560], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7295, 0.7274, 0.7730, 0.1578], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1209, 0.4816, 0.4415, 0.7832], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6816, 0.7123, 0.4933, 0.5083], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1479, 0.4779, 0.1710, 0.3992], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7677, 0.6762, 0.4775, 0.5787], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7102, 0.7771, 0.3628, 0.3864], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1370, 0.2999, 0.2604, 0.6682], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4579, 0.0949, 0.2892, 0.7601], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2540, 0.7061, 0.4059, 0.8023], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4468, 0.5955, 0.4082, 0.6471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1387, 0.6826, 0.5135, 0.6440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5848, 0.2990, 0.8220, 0.6565], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7581, 0.2211, 0.7817, 0.4209], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2123, 0.7983, 0.3216, 0.7445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6328, 0.1495, 0.0878, 0.0865], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7794, 0.6090, 0.1765, 0.3712], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5401, 0.2435, 0.3541, 0.7716], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5289, 0.6494, 0.1847, 0.5238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3284, 0.3220, 0.6439, 0.6410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1868, 0.0648, 0.6198, 0.2823], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2548, 0.3619, 0.8123, 0.1979], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4196, 0.2869, 0.6223, 0.6060], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7469, 0.4800, 0.5682, 0.7570], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5955, 0.1226, 0.3430, 0.5791], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1502, 0.0534, 0.2113, 0.5122], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4103, 0.5740, 0.0924, 0.3291], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8175, 0.3657, 0.7758, 0.4897], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3707, 0.2244, 0.7133, 0.5656], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4493, 0.4879, 0.7421, 0.4794], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2641, 0.0969, 0.4023, 0.4137], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3820, 0.7856, 0.2234, 0.6501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6202, 0.7133, 0.8193, 0.4579], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4715, 0.6346, 0.8396, 0.5125], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7357, 0.2774, 0.5868, 0.7689], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5537, 0.6882, 0.4402, 0.6350], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2418, 0.7294, 0.7597, 0.5152], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6157, 0.1008, 0.0957, 0.0852], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6834, 0.4099, 0.5942, 0.5753], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2353, 0.2676, 0.3613, 0.2080], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4281, 0.8664, 0.7169, 0.6610], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2634, 0.3218, 0.4007, 0.7539], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3609, 0.6999, 0.2727, 0.2204], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5400, 0.3979, 0.4324, 0.7277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4934, 0.3574, 0.1097, 0.7020], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2632, 0.6064, 0.1214, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8509, 0.6410, 0.5870, 0.3712], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3181, 0.1343, 0.0970, 0.3194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3704, 0.4859, 0.8371, 0.6160], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1304, 0.7732, 0.3817, 0.3131], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6627, 0.5664, 0.2940, 0.8196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4398, 0.1414, 0.4828, 0.4489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4887, 0.3773, 0.2340, 0.4411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2235, 0.7091, 0.6843, 0.5536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2660, 0.0771, 0.3138, 0.5250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8754, 0.8223, 0.6770, 0.8885], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2101, 0.7302, 0.4096, 0.4360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5432, 0.7655, 0.4865, 0.2445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7490, 0.6303, 0.4673, 0.3848], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7703, 0.7369, 0.5271, 0.3328], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7366, 0.7191, 0.5124, 0.1990], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7411, 0.8248, 0.8183, 0.4800], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4538, 0.2715, 0.7123, 0.3157], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4238, 0.1974, 0.4836, 0.5672], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4791, 0.1272, 0.7967, 0.7632], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3753, 0.5946, 0.5418, 0.5186], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4082, 0.3741, 0.1439, 0.7931], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2419, 0.6171, 0.1425, 0.1902], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2486, 0.6554, 0.3898, 0.6586], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4712, 0.1230, 0.3537, 0.7513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1532, 0.2390, 0.4110, 0.4315], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6092, 0.8025, 0.3572, 0.7879], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4937, 0.1868, 0.6119, 0.5984], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6060, 0.3167, 0.0704, 0.3472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2613, 0.3923, 0.7533, 0.2104], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1205, 0.4730, 0.7900, 0.6851], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6267, 0.2443, 0.5318, 0.3462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4456, 0.3040, 0.3810, 0.7651], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3667, 0.6003, 0.5005, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4320, 0.6168, 0.5057, 0.1427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2424, 0.5151, 0.4636, 0.3002], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2447, 0.3542, 0.5395, 0.0809], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6376, 0.1865, 0.1171, 0.2225], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6726, 0.3297, 0.5526, 0.6153], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1797, 0.6330, 0.5324, 0.3972], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7438, 0.7511, 0.7557, 0.4103], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6357, 0.8911, 0.8336, 0.7258], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3903, 0.1657, 0.6161, 0.1953], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2702, 0.1011, 0.2105, 0.1417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3343, 0.6051, 0.8053, 0.3685], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2289, 0.2466, 0.5558, 0.4898], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1108, 0.1922, 0.8196, 0.6470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7204, 0.7682, 0.6560, 0.2676], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2933, 0.3474, 0.0983, 0.6385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4406, 0.0872, 0.4366, 0.1493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4701, 0.7909, 0.6479, 0.3073], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7368, 0.1411, 0.1286, 0.5327], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8770, 0.4973, 0.5804, 0.7838], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7472, 0.3336, 0.6859, 0.8622], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7792, 0.2256, 0.4989, 0.5671], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5883, 0.5957, 0.7582, 0.3083], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4319, 0.7112, 0.3093, 0.7099], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5922, 0.2030, 0.6921, 0.5040], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1574, 0.4891, 0.1557, 0.0721], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1855, 0.8652, 0.6091, 0.8607], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6486, 0.5655, 0.4651, 0.4839], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5647, 0.6911, 0.1926, 0.3574], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5549, 0.3469, 0.2456, 0.8142], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0624, 0.5659, 0.0687, 0.5031], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6981, 0.4539, 0.3391, 0.6742], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8510, 0.4504, 0.7219, 0.6392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0953, 0.7032, 0.5276, 0.3835], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7433, 0.5008, 0.4362, 0.3907], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2024, 0.6668, 0.2765, 0.5396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7643, 0.5160, 0.3856, 0.7363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1642, 0.0930, 0.6891, 0.2674], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7282, 0.7564, 0.7099, 0.7771], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4635, 0.1358, 0.5844, 0.7719], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6948, 0.5261, 0.7569, 0.8840], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5534, 0.8276, 0.4372, 0.7076], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2505, 0.1353, 0.6259, 0.6953], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8395, 0.5307, 0.1597, 0.6427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1630, 0.4372, 0.8135, 0.5285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3007, 0.0494, 0.1507, 0.2140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3561, 0.1791, 0.1322, 0.7443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4867, 0.7813, 0.4520, 0.5293], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7881, 0.5314, 0.5152, 0.6926], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8240, 0.1105, 0.3447, 0.5325], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7903, 0.8417, 0.5476, 0.5970], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1066, 0.0410, 0.1941, 0.3955], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7551, 0.2644, 0.6262, 0.3293], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5400, 0.7813, 0.5549, 0.1421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1921, 0.1860, 0.6762, 0.1176], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3217, 0.4995, 0.4353, 0.1222], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6741, 0.8063, 0.1682, 0.8156], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6720, 0.7634, 0.8212, 0.3424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2392, 0.8012, 0.6810, 0.4941], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6095, 0.7234, 0.4585, 0.1038], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1138, 0.6511, 0.6112, 0.5993], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4576, 0.6231, 0.1838, 0.6972], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5060, 0.4465, 0.5343, 0.7331], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4016, 0.4233, 0.4557, 0.0765], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7575, 0.5709, 0.6941, 0.2589], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8279, 0.5175, 0.7415, 0.2766], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2130, 0.0947, 0.2338, 0.5927], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7003, 0.6105, 0.3240, 0.5648], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5507, 0.7149, 0.7170, 0.1155], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1060, 0.4043, 0.2112, 0.4399], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1908, 0.1487, 0.2063, 0.6495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1124, 0.4153, 0.6775, 0.3706], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1989, 0.8056, 0.4038, 0.7192], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4629, 0.7242, 0.6111, 0.2464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5754, 0.6813, 0.1342, 0.7109], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2947, 0.1559, 0.2548, 0.7148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4149, 0.3740, 0.3403, 0.6962], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8156, 0.1695, 0.6397, 0.2279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2821, 0.2306, 0.8092, 0.2702], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3572, 0.5115, 0.1214, 0.7274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3011, 0.4495, 0.7918, 0.7593], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3480, 0.6659, 0.7764, 0.3077], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5824, 0.6134, 0.8440, 0.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2326, 0.7357, 0.3409, 0.2157], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5318, 0.6073, 0.4536, 0.8271], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4613, 0.7550, 0.6573, 0.6408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2522, 0.7355, 0.2752, 0.3618], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2224, 0.1210, 0.7754, 0.7110], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5526, 0.1224, 0.1721, 0.7547], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5055, 0.2537, 0.8458, 0.7141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4577, 0.6693, 0.4915, 0.7237], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8183, 0.8710, 0.4798, 0.8071], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3858, 0.1445, 0.6729, 0.5843], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7648, 0.5440, 0.3799, 0.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5998, 0.6687, 0.5832, 0.1978], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3784, 0.8035, 0.4907, 0.1974], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1278, 0.2911, 0.0952, 0.7989], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1794, 0.3387, 0.4463, 0.2507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2526, 0.1977, 0.1283, 0.4164], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8073, 0.3423, 0.3307, 0.1571], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3234, 0.1721, 0.2138, 0.7461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4147, 0.3155, 0.8336, 0.4903], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2684, 0.4687, 0.4107, 0.7662], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7108, 0.6234, 0.3420, 0.4226], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8082, 0.2950, 0.6349, 0.1637], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2519, 0.4800, 0.6534, 0.3560], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1425, 0.1189, 0.0631, 0.2807], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4562, 0.4194, 0.6480, 0.0993], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5215, 0.6864, 0.5830, 0.5396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5672, 0.6626, 0.8143, 0.1965], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1452, 0.0531, 0.3566, 0.0374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5914, 0.1720, 0.5204, 0.1829], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1346, 0.1855, 0.4342, 0.3520], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2645, 0.2231, 0.5938, 0.7679], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3738, 0.8317, 0.4343, 0.5320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3388, 0.5428, 0.3158, 0.5307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2252, 0.7256, 0.7863, 0.3668], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5908, 0.4777, 0.6904, 0.7316], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7801, 0.3042, 0.3758, 0.5408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8529, 0.3510, 0.6668, 0.5396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5214, 0.4045, 0.1969, 0.1327], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6489, 0.4411, 0.1933, 0.5371], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4809, 0.1367, 0.1071, 0.4091], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5893, 0.3395, 0.3150, 0.4486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1163, 0.5373, 0.2124, 0.1826], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1118, 0.6757, 0.7131, 0.2698], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1275, 0.5500, 0.4668, 0.3836], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8633, 0.5196, 0.5440, 0.8691], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3875, 0.2483, 0.5347, 0.7937], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4132, 0.6189, 0.7926, 0.5584], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3026, 0.6663, 0.4050, 0.7138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7722, 0.6995, 0.2888, 0.8322], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6650, 0.1996, 0.3454, 0.3923], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6200, 0.6485, 0.7531, 0.2495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5801, 0.3370, 0.7607, 0.7636], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2101, 0.7164, 0.1208, 0.2280], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5076, 0.1409, 0.6375, 0.5140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4483, 0.6139, 0.7490, 0.5702], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2174, 0.5237, 0.6786, 0.6137], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5152, 0.8044, 0.4311, 0.4401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7440, 0.4342, 0.8129, 0.8736], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1705, 0.4209, 0.6066, 0.3973], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3639, 0.3823, 0.7691, 0.3989], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3150, 0.3426, 0.8393, 0.7968], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1679, 0.4302, 0.6859, 0.2509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2610, 0.1662, 0.5719, 0.4344], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2285, 0.6311, 0.1547, 0.2830], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6487, 0.3586, 0.4291, 0.6739], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8166, 0.7814, 0.8195, 0.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4894, 0.7201, 0.2001, 0.2360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5957, 0.5344, 0.6244, 0.0935], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7396, 0.6751, 0.3986, 0.5755], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5072, 0.6733, 0.3898, 0.5751], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4875, 0.2670, 0.5274, 0.6705], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1081, 0.5699, 0.3013, 0.5962], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2612, 0.1880, 0.6178, 0.5020], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2384, 0.1640, 0.1200, 0.5447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3272, 0.1466, 0.4931, 0.0552], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5361, 0.5409, 0.1505, 0.6571], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6638, 0.4277, 0.7875, 0.6756], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8257, 0.7268, 0.7755, 0.5273], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5806, 0.1541, 0.7010, 0.8528], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7352, 0.2240, 0.8426, 0.5994], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6062, 0.5027, 0.7295, 0.8731], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7366, 0.2742, 0.7772, 0.6220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2473, 0.2347, 0.3648, 0.1471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5438, 0.0971, 0.0534, 0.0398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2130, 0.4060, 0.0767, 0.1337], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7792, 0.4094, 0.5870, 0.2510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4276, 0.1606, 0.4104, 0.3112], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7554, 0.6665, 0.7440, 0.2679], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6442, 0.8388, 0.7954, 0.7689], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5104, 0.1795, 0.3404, 0.7624], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2133, 0.1765, 0.5119, 0.5836], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1929, 0.6932, 0.3120, 0.3523], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6213, 0.5801, 0.4506, 0.5058], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1116, 0.8169, 0.7690, 0.4267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8460, 0.1267, 0.7982, 0.4233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7334, 0.4570, 0.3971, 0.5371], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6295, 0.7859, 0.7801, 0.6768], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7585, 0.6856, 0.8700, 0.5736], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2731, 0.1949, 0.0843, 0.3054], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4890, 0.1068, 0.4005, 0.5670], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3720, 0.1418, 0.0980, 0.6184], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1642, 0.2910, 0.6290, 0.4611], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6039, 0.2777, 0.1422, 0.8012], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3405, 0.4433, 0.7087, 0.5897], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6256, 0.8055, 0.5629, 0.8297], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5845, 0.1195, 0.5132, 0.5181], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6995, 0.5877, 0.7366, 0.4141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5968, 0.8131, 0.8724, 0.4194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3805, 0.4074, 0.3004, 0.4138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2745, 0.7256, 0.2413, 0.1608], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7862, 0.6529, 0.2990, 0.6419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4511, 0.0988, 0.5882, 0.5762], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5004, 0.8304, 0.2979, 0.6882], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7654, 0.2662, 0.7692, 0.4158], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8045, 0.7395, 0.3766, 0.3231], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5907, 0.3676, 0.4367, 0.2949], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7466, 0.8404, 0.8497, 0.4709], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3163, 0.3710, 0.6155, 0.0946], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3173, 0.2307, 0.6011, 0.3254], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3915, 0.5755, 0.4209, 0.1270], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3021, 0.6559, 0.7330, 0.3106], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5949, 0.0975, 0.4304, 0.6342], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5123, 0.5416, 0.2848, 0.6520], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3442, 0.6301, 0.7098, 0.4804], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1510, 0.7546, 0.1023, 0.4512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2915, 0.7489, 0.1106, 0.2173], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2462, 0.1187, 0.3954, 0.1950], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4700, 0.4659, 0.1463, 0.3641], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5297, 0.4195, 0.2472, 0.4134], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8115, 0.5868, 0.4484, 0.1062], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4963, 0.7856, 0.3416, 0.6564], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2135, 0.6977, 0.3711, 0.3136], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7483, 0.2082, 0.0763, 0.1898], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6358, 0.3954, 0.4187, 0.1025], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4110, 0.1705, 0.7564, 0.8148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3130, 0.7084, 0.2328, 0.6701], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7690, 0.3734, 0.6311, 0.2755], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8707, 0.8546, 0.3617, 0.7167], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1636, 0.4786, 0.7394, 0.7574], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5421, 0.5908, 0.5165, 0.3808], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5010, 0.6354, 0.2829, 0.2240], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6421, 0.5909, 0.6347, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1079, 0.4300, 0.6655, 0.5238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1846, 0.3944, 0.6499, 0.1210], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3891, 0.7622, 0.8144, 0.3684], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6667, 0.2455, 0.7329, 0.6659], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3399, 0.3343, 0.7761, 0.3671], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3929, 0.3125, 0.5266, 0.3263], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2125, 0.2604, 0.1191, 0.3593], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6097, 0.3746, 0.6432, 0.3148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2637, 0.2121, 0.4757, 0.6336], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6859, 0.6405, 0.2950, 0.3538], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4954, 0.2217, 0.2477, 0.0764], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4993, 0.1287, 0.3280, 0.5718], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3027, 0.5106, 0.3627, 0.0775], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8012, 0.2696, 0.1464, 0.1146], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3795, 0.3995, 0.1645, 0.6104], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3310, 0.5531, 0.6320, 0.2712], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5157, 0.5756, 0.7866, 0.5702], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1561, 0.7286, 0.7342, 0.1465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5460, 0.8046, 0.6739, 0.4043], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3196, 0.6647, 0.2952, 0.1851], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5481, 0.3206, 0.6610, 0.5021], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4224, 0.3199, 0.1561, 0.4584], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5955, 0.8139, 0.1572, 0.7055], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5435, 0.6605, 0.2421, 0.5312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2283, 0.5428, 0.3173, 0.5372], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3593, 0.1373, 0.7687, 0.0821], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5271, 0.5673, 0.3040, 0.7087], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2958, 0.8036, 0.5612, 0.1920], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7709, 0.4293, 0.8233, 0.1098], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1042, 0.7726, 0.5377, 0.5838], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5157, 0.6827, 0.4169, 0.7876], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8392, 0.7163, 0.7318, 0.3034], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7856, 0.2272, 0.6013, 0.6229], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0865, 0.2996, 0.0989, 0.2342], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1349, 0.8410, 0.7348, 0.4923], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4988, 0.4893, 0.6060, 0.7856], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6727, 0.4728, 0.5864, 0.2618], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7860, 0.6329, 0.2157, 0.3906], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7154, 0.4820, 0.4137, 0.3494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2476, 0.3120, 0.5472, 0.4679], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4399, 0.2331, 0.6889, 0.4742], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1672, 0.7319, 0.4972, 0.3762], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2190, 0.3062, 0.6561, 0.1672], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8150, 0.5102, 0.3948, 0.6743], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5825, 0.5324, 0.8474, 0.6015], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7814, 0.2170, 0.1330, 0.5578], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2514, 0.7757, 0.1545, 0.3771], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6601, 0.8083, 0.2707, 0.6718], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1827, 0.7507, 0.2482, 0.6518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3161, 0.1743, 0.2033, 0.7650], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1959, 0.4447, 0.2226, 0.3834], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1393, 0.6440, 0.3308, 0.5135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4441, 0.8012, 0.5799, 0.1483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0911, 0.4401, 0.7473, 0.1433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6520, 0.3814, 0.1218, 0.4448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2026, 0.7166, 0.0976, 0.5842], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7378, 0.5606, 0.7097, 0.3108], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6404, 0.8275, 0.1710, 0.3169], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4441, 0.3836, 0.2495, 0.7143], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6815, 0.7105, 0.3389, 0.4855], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5001, 0.3171, 0.4734, 0.4277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6560, 0.4745, 0.3325, 0.1043], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3905, 0.3212, 0.7684, 0.1908], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7247, 0.1952, 0.6369, 0.3559], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1967, 0.2801, 0.5190, 0.2232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6648, 0.3733, 0.7026, 0.7016], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4931, 0.3078, 0.8158, 0.7986], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3394, 0.2275, 0.1264, 0.1395], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7935, 0.4451, 0.7648, 0.3962], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3327, 0.4055, 0.7783, 0.3974], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2941, 0.3378, 0.2942, 0.4292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7575, 0.7857, 0.1253, 0.5126], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5420, 0.8400, 0.2077, 0.7713], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7860, 0.1516, 0.3280, 0.6377], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0865, 0.3697, 0.3530, 0.1598], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7483, 0.4782, 0.8403, 0.3680], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7840, 0.2901, 0.6720, 0.4145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2716, 0.6043, 0.3114, 0.5181], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7363, 0.4946, 0.7190, 0.5382], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1455, 0.2302, 0.2299, 0.6048], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6337, 0.2713, 0.8056, 0.4177], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3669, 0.2389, 0.4905, 0.1554], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7107, 0.1054, 0.4394, 0.6330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8374, 0.5011, 0.8548, 0.5259], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7974, 0.1039, 0.0840, 0.4721], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1145, 0.5202, 0.3497, 0.6479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1406, 0.2591, 0.5025, 0.1603], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2908, 0.5699, 0.4095, 0.4646], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3903, 0.7565, 0.1526, 0.2364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0670, 0.7481, 0.2442, 0.1155], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0854, 0.6959, 0.6045, 0.0775], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5903, 0.1253, 0.3731, 0.1493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7807, 0.7160, 0.3651, 0.5197], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8128, 0.8474, 0.2664, 0.4100], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3388, 0.1503, 0.6918, 0.4768], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7816, 0.7771, 0.7295, 0.3185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4704, 0.4488, 0.3984, 0.0848], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8548, 0.4334, 0.6718, 0.8727], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0444, 0.1517, 0.1526, 0.4880], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5108, 0.3641, 0.2369, 0.5748], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0932, 0.6148, 0.1713, 0.5355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8467, 0.3336, 0.7096, 0.4019], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7876, 0.3154, 0.6757, 0.1324], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3430, 0.5207, 0.2421, 0.5073], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0748, 0.3277, 0.2786, 0.4305], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6679, 0.4543, 0.4789, 0.3574], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2262, 0.8055, 0.3696, 0.3937], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7682, 0.4084, 0.1763, 0.4067], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8107, 0.3484, 0.4510, 0.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5735, 0.7382, 0.5206, 0.6524], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5771, 0.2098, 0.1557, 0.2086], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2121, 0.2658, 0.4597, 0.2488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7049, 0.2624, 0.8179, 0.7367], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2510, 0.7127, 0.3794, 0.3947], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4336, 0.3092, 0.3694, 0.5854], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2913, 0.5582, 0.5820, 0.2711], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3991, 0.7129, 0.4115, 0.6791], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8498, 0.5619, 0.5685, 0.3793], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6689, 0.2791, 0.1689, 0.2944], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2047, 0.2249, 0.5988, 0.5968], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1941, 0.5445, 0.1985, 0.4215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6461, 0.2680, 0.2506, 0.6084], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3506, 0.3933, 0.2245, 0.3428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2701, 0.6431, 0.3484, 0.6770], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5437, 0.4868, 0.4832, 0.4199], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3374, 0.4884, 0.2581, 0.1585], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5417, 0.2075, 0.6171, 0.5798], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7100, 0.6423, 0.7931, 0.4953], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8090, 0.8146, 0.3084, 0.2664], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7423, 0.4283, 0.7084, 0.4887], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2647, 0.6884, 0.2478, 0.7605], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3592, 0.3947, 0.1636, 0.2295], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5207, 0.4802, 0.1656, 0.6609], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1702, 0.2820, 0.3839, 0.6632], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2651, 0.5685, 0.2622, 0.4610], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2149, 0.1704, 0.4362, 0.2550], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4580, 0.7003, 0.2571, 0.4849], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6612, 0.4073, 0.5226, 0.5768], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5290, 0.5468, 0.7290, 0.6067], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6535, 0.2516, 0.1068, 0.4605], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6320, 0.7768, 0.5138, 0.8682], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5730, 0.6735, 0.2815, 0.6155], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3764, 0.3188, 0.3814, 0.3675], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1750, 0.2762, 0.1863, 0.3549], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2510, 0.6376, 0.5622, 0.6040], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6918, 0.6375, 0.3606, 0.5354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7601, 0.7748, 0.6495, 0.6876], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2253, 0.3526, 0.6492, 0.2683], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l2_norms = []\n",
    "for _ in range(10):\n",
    "  index = np.random.randint(1, N, size=100)\n",
    "\n",
    "  synthetic_x = []\n",
    "  for i in index:\n",
    "    model = SC(N, P, T)\n",
    "    optimizer = torch.optim.SGD([model.h, model.L, model.delta, model.gamma],\n",
    "                              lr=0.01)\n",
    "    mask = torch.ones(N, T)\n",
    "    mask[i, :] = 0\n",
    "\n",
    "    Y_t_local = torch.multiply(Y_t, mask)\n",
    "\n",
    "    for _ in range(3000):\n",
    "      optimizer.zero_grad()\n",
    "      loss = model.forward(X_t, Y_t_local)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    print(model.L[i, :])\n",
    "    synthetic_x.append(model.L[i, :].detach().numpy())\n",
    "    \n",
    "  err = (Y.iloc[index] - np.array(synthetic_x)).to_numpy()\n",
    "  l2_norms.append(np.linalg.norm(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.23255768478882"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.var(l2_norms)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1541, 42)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyangzhu/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:395: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  check_array(X, dtype=np.int)\n",
      "/Users/chenyangzhu/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "/Users/chenyangzhu/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.read_csv(\"../data/synthetic_matrix.csv\")\n",
    "X = pd.read_csv(\"../data/objects_c.csv\")\n",
    "X = X[['id', 'category_code']]\n",
    "large = Y.merge(X, left_on='id', right_on='id', how='left')\n",
    "\n",
    "Y = large.iloc[:, 3:7]\n",
    "X = large.iloc[:, -1]\n",
    "X = X.fillna(\"others\")\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "X = enc.fit_transform(X.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i in range(31):\n",
    "  embeddings.append(pd.read_csv(f\"../data/embedding/batch-{i}.csv\", header=None, delimiter=\" \").to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X, np.concatenate(embeddings)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T = Y.shape\n",
    "_, P = X.shape\n",
    "\n",
    "X_t = torch.tensor(X).double()\n",
    "Y_t = torch.tensor(Y.to_numpy()).double()\n",
    "\n",
    "# Creat mask\n",
    "mask = pd.read_csv(\"../data/mask.csv\", index_col=0).to_numpy()\n",
    "Y_t = torch.multiply(Y_t, torch.tensor(mask, dtype=torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SC(N, P, T)\n",
    "optimizer = torch.optim.SGD([model.h, model.L, model.delta, model.gamma],\n",
    "                            lr=0.1)\n",
    "\n",
    "l_list = []\n",
    "for _ in range(300):\n",
    "  optimizer.zero_grad()\n",
    "  loss = model.forward(X_t, Y_t)\n",
    "  l_list.append(loss.detach().numpy())\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2002, 0.2382, 0.5123, 0.6657],\n",
       "        [0.1767, 0.2479, 0.3629, 0.2777],\n",
       "        [0.6537, 0.6243, 0.2776, 0.4595],\n",
       "        ...,\n",
       "        [0.5959, 0.6207, 0.2266, 0.3389],\n",
       "        [0.6814, 0.1454, 0.6324, 0.5234],\n",
       "        [0.6154, 0.7843, 0.3957, 0.4861]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc9f6428e90>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l_list)\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/L2.csv', model.L.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3875, 0.6831, 0.0878, 0.0983], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4377, 0.7045, 0.2124, 0.4968], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0960, 0.0917, 0.1102, 0.5410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5489, 0.7297, 0.5921, 0.5850], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0647, 0.3067, 0.3453, 0.1112], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5429, 0.7386, 0.6839, 0.8535], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8020, 0.5524, 0.3915, 0.3712], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0753, 0.0645, 0.6756, 0.0541], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8173, 0.6528, 0.1329, 0.8556], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7486, 0.3691, 0.5756, 0.3033], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6421, 0.4587, 0.7689, 0.2909], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2906, 0.1429, 0.4730, 0.5973], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4855, 0.5272, 0.3333, 0.7441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6662, 0.6174, 0.2366, 0.2781], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0746, 0.1433, 0.7522, 0.4380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4151, 0.2279, 0.0989, 0.6507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6989, 0.8902, 0.8937, 0.6981], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2118, 0.1606, 0.1526, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0968, 0.7173, 0.4434, 0.3965], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1409, 0.7395, 0.6635, 0.4699], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5812, 0.4465, 0.1212, 0.3898], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1657, 0.1066, 0.6036, 0.6229], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6862, 0.7209, 0.2851, 0.7570], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4984, 0.5321, 0.0907, 0.5560], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6828, 0.7470, 0.5206, 0.3794], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2168, 0.7287, 0.8036, 0.3001], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4739, 0.6673, 0.7671, 0.2093], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2391, 0.7651, 0.5895, 0.3592], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5690, 0.4039, 0.7351, 0.5367], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3171, 0.6638, 0.3039, 0.3711], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6314, 0.4881, 0.6800, 0.7409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4952, 0.7072, 0.2504, 0.2023], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4772, 0.2332, 0.0577, 0.2599], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7636, 0.6251, 0.1238, 0.6418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3458, 0.3634, 0.1816, 0.1785], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2611, 0.6870, 0.7566, 0.2348], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1782, 0.1290, 0.7193, 0.5120], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5027, 0.0830, 0.2871, 0.4865], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5409, 0.8290, 0.7855, 0.7052], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6985, 0.3572, 0.4946, 0.6185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6389, 0.5426, 0.3477, 0.2818], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5297, 0.6458, 0.6474, 0.2052], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6076, 0.4182, 0.4733, 0.7187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6405, 0.3742, 0.3002, 0.4915], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2906, 0.6195, 0.2651, 0.4603], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1943, 0.0830, 0.2878, 0.1291], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0922, 0.2794, 0.7330, 0.1427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3589, 0.3005, 0.4398, 0.2058], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6316, 0.3319, 0.6008, 0.5517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3239, 0.5125, 0.7839, 0.1789], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5348, 0.5846, 0.1685, 0.0723], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2461, 0.3749, 0.2013, 0.2238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5655, 0.6818, 0.1825, 0.7824], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3875, 0.3699, 0.7096, 0.3752], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2088, 0.1948, 0.3609, 0.0515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3641, 0.2396, 0.7900, 0.0952], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6897, 0.6557, 0.8592, 0.4815], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3215, 0.2678, 0.1477, 0.6903], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2845, 0.8227, 0.5438, 0.5677], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0873, 0.1384, 0.4559, 0.7903], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2809, 0.7904, 0.3487, 0.8140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6483, 0.2321, 0.5086, 0.1337], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7696, 0.3605, 0.5613, 0.5705], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3589, 0.8154, 0.2679, 0.7470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7057, 0.6527, 0.3019, 0.4595], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2029, 0.4400, 0.7670, 0.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1811, 0.1326, 0.3121, 0.3865], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1994, 0.1322, 0.3256, 0.2199], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3761, 0.5849, 0.3700, 0.3616], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5650, 0.8280, 0.5962, 0.5161], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3606, 0.2007, 0.1304, 0.5762], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8342, 0.2528, 0.8256, 0.3750], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6016, 0.2115, 0.3936, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3729, 0.5274, 0.4274, 0.2208], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3665, 0.4825, 0.4937, 0.0741], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2184, 0.7894, 0.2062, 0.3870], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2261, 0.3995, 0.6664, 0.0767], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5948, 0.3788, 0.4054, 0.4180], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3458, 0.2981, 0.4143, 0.1477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4244, 0.8650, 0.8778, 0.5825], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7039, 0.7634, 0.2168, 0.8201], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5764, 0.5352, 0.3949, 0.2154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0900, 0.1580, 0.2382, 0.7926], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5452, 0.8301, 0.7105, 0.6517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6943, 0.2952, 0.0852, 0.6209], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5644, 0.4213, 0.4648, 0.1908], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7656, 0.0857, 0.3924, 0.2197], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5579, 0.1445, 0.4325, 0.2477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6246, 0.2345, 0.2196, 0.1670], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2727, 0.7582, 0.5883, 0.6933], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4564, 0.6905, 0.4135, 0.2606], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1683, 0.6275, 0.6934, 0.3734], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4474, 0.6972, 0.6728, 0.4840], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7774, 0.2200, 0.7272, 0.7674], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7570, 0.7600, 0.8603, 0.8883], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2460, 0.1696, 0.7628, 0.4402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8553, 0.3240, 0.7721, 0.8393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4038, 0.2297, 0.5166, 0.2530], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5745, 0.2828, 0.3217, 0.1069], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5890, 0.1445, 0.5981, 0.5931], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7463, 0.3109, 0.3009, 0.6722], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2517, 0.4983, 0.7072, 0.1328], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2091, 0.8131, 0.6086, 0.2624], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1405, 0.6158, 0.8436, 0.7988], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2946, 0.4811, 0.4382, 0.3285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2924, 0.5533, 0.4355, 0.3114], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7813, 0.2576, 0.5132, 0.6847], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1198, 0.7803, 0.1793, 0.5991], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1179, 0.2129, 0.6045, 0.7040], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7910, 0.6309, 0.5100, 0.5351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1051, 0.4324, 0.1371, 0.3997], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5490, 0.1909, 0.6086, 0.2669], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6473, 0.2092, 0.5892, 0.7345], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1160, 0.5435, 0.4201, 0.7813], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3107, 0.4545, 0.3254, 0.1089], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4806, 0.2806, 0.2872, 0.2322], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4184, 0.6604, 0.1293, 0.5470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3231, 0.3888, 0.3868, 0.6235], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7534, 0.3247, 0.7204, 0.6092], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2769, 0.4534, 0.2244, 0.7652], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7561, 0.8633, 0.3745, 0.8398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3511, 0.5101, 0.4244, 0.6958], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7122, 0.2183, 0.2010, 0.5332], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6757, 0.7861, 0.4050, 0.1494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7921, 0.8387, 0.4560, 0.7369], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4884, 0.1156, 0.3844, 0.1013], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2395, 0.3988, 0.1058, 0.2959], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2044, 0.7698, 0.3674, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7702, 0.7629, 0.2613, 0.4309], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4349, 0.6589, 0.7411, 0.4394], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7662, 0.5478, 0.3065, 0.5354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5073, 0.1277, 0.0846, 0.4331], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6249, 0.8146, 0.8483, 0.3912], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1882, 0.2595, 0.3862, 0.1477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5661, 0.6489, 0.1466, 0.4685], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8634, 0.7411, 0.4323, 0.8316], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2506, 0.2985, 0.1720, 0.6573], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2864, 0.6338, 0.4124, 0.2321], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6816, 0.8331, 0.2639, 0.1852], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8422, 0.6503, 0.5312, 0.1705], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3927, 0.4427, 0.1592, 0.3007], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3295, 0.4359, 0.2878, 0.3869], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6145, 0.3488, 0.7239, 0.2786], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1007, 0.4362, 0.1523, 0.2769], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4095, 0.1574, 0.1262, 0.0437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8833, 0.7264, 0.7991, 0.6202], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3375, 0.1248, 0.3429, 0.2000], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4032, 0.1661, 0.5818, 0.6842], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5785, 0.5269, 0.4215, 0.2388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5574, 0.0622, 0.1700, 0.4382], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5705, 0.6241, 0.3106, 0.5802], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1950, 0.0953, 0.4827, 0.3516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0563, 0.7174, 0.1313, 0.1909], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7532, 0.8429, 0.1612, 0.5779], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7899, 0.1555, 0.5771, 0.6390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6763, 0.1507, 0.1022, 0.5861], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8428, 0.2557, 0.8432, 0.8119], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4923, 0.7131, 0.5961, 0.6808], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3921, 0.1693, 0.1611, 0.3502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8130, 0.5597, 0.3937, 0.5839], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7531, 0.7880, 0.6323, 0.1812], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7287, 0.3204, 0.7483, 0.2405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5635, 0.6638, 0.5953, 0.7722], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7525, 0.7392, 0.5097, 0.4033], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8301, 0.2013, 0.6809, 0.2177], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5757, 0.6557, 0.4360, 0.4710], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3599, 0.2881, 0.7861, 0.4018], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7571, 0.2480, 0.6562, 0.2736], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6716, 0.8142, 0.3603, 0.8693], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3489, 0.1178, 0.5917, 0.6424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6941, 0.5268, 0.4797, 0.5694], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1612, 0.4512, 0.0892, 0.2051], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3105, 0.2663, 0.0682, 0.4282], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8368, 0.1249, 0.5452, 0.5556], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3557, 0.1750, 0.5226, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3787, 0.5292, 0.4633, 0.1005], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6364, 0.1132, 0.2761, 0.1364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3952, 0.6581, 0.1095, 0.6404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5944, 0.3654, 0.5141, 0.1292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5312, 0.7631, 0.5386, 0.1172], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0942, 0.4611, 0.7650, 0.1865], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0808, 0.1537, 0.4584, 0.2819], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6440, 0.2625, 0.7030, 0.7068], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3455, 0.7208, 0.7039, 0.8332], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2591, 0.5201, 0.6841, 0.5263], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7087, 0.6377, 0.7771, 0.3895], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5303, 0.8499, 0.6485, 0.3843], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4590, 0.7389, 0.7002, 0.2791], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0713, 0.2258, 0.0907, 0.1816], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5786, 0.7748, 0.3719, 0.3470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5171, 0.5039, 0.4635, 0.7350], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1013, 0.8148, 0.3031, 0.5675], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5318, 0.5815, 0.7147, 0.4003], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3652, 0.2146, 0.6214, 0.4038], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4306, 0.5791, 0.7655, 0.6833], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7536, 0.1871, 0.8280, 0.3939], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4325, 0.6982, 0.3213, 0.1611], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6486, 0.3572, 0.4662, 0.6026], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4167, 0.6979, 0.2534, 0.3108], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3316, 0.1556, 0.3994, 0.5647], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1376, 0.2868, 0.3953, 0.1528], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8036, 0.1552, 0.4416, 0.3039], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3523, 0.5093, 0.7179, 0.3279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4961, 0.3515, 0.6712, 0.3810], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2894, 0.7649, 0.6388, 0.1166], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1281, 0.1145, 0.5854, 0.4939], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6270, 0.2521, 0.5909, 0.7219], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5579, 0.2556, 0.3826, 0.3963], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3649, 0.2098, 0.0791, 0.7763], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4562, 0.2859, 0.1170, 0.0550], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0595, 0.0962, 0.4498, 0.2916], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4055, 0.6751, 0.7214, 0.8326], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1141, 0.6165, 0.8112, 0.6728], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6978, 0.6317, 0.1456, 0.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1712, 0.5043, 0.8354, 0.3715], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6806, 0.3957, 0.2016, 0.6312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2182, 0.5244, 0.4952, 0.7624], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2758, 0.7382, 0.4665, 0.5824], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6995, 0.8335, 0.3642, 0.4511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5485, 0.8079, 0.1018, 0.2090], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4479, 0.1592, 0.6671, 0.1162], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5979, 0.2452, 0.7732, 0.2051], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7311, 0.2153, 0.8322, 0.4652], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7796, 0.4542, 0.3713, 0.1769], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7667, 0.1661, 0.1033, 0.8232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2455, 0.6505, 0.3403, 0.3384], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5559, 0.2272, 0.6986, 0.3287], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6606, 0.5333, 0.2944, 0.5904], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4666, 0.2153, 0.2090, 0.3037], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7525, 0.5214, 0.7683, 0.2758], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6955, 0.2577, 0.3756, 0.5122], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3699, 0.7650, 0.1382, 0.6348], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6357, 0.2584, 0.8069, 0.1296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6015, 0.1453, 0.5444, 0.8374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2070, 0.2090, 0.4840, 0.5101], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4515, 0.3770, 0.1815, 0.4914], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6735, 0.4738, 0.8080, 0.4998], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4291, 0.2401, 0.0883, 0.7649], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6950, 0.7039, 0.2443, 0.4765], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6403, 0.3963, 0.1717, 0.6326], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3223, 0.5931, 0.3464, 0.3116], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6911, 0.2529, 0.6479, 0.7993], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8600, 0.7786, 0.6894, 0.3317], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8037, 0.1934, 0.2691, 0.4475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4394, 0.0631, 0.0839, 0.2636], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5600, 0.2150, 0.4338, 0.2841], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5140, 0.5234, 0.6381, 0.4887], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4762, 0.4813, 0.1414, 0.2032], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1046, 0.0537, 0.7865, 0.1252], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8192, 0.5640, 0.1534, 0.6582], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5929, 0.6766, 0.2983, 0.1607], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7008, 0.5756, 0.5781, 0.1826], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5325, 0.2805, 0.4338, 0.5877], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7410, 0.2794, 0.2552, 0.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1808, 0.3414, 0.4464, 0.1192], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2368, 0.4571, 0.2205, 0.5035], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2693, 0.6278, 0.5243, 0.1388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1625, 0.5380, 0.2728, 0.6536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2545, 0.5473, 0.5246, 0.7586], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6142, 0.8485, 0.8303, 0.3874], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3371, 0.5738, 0.6710, 0.6520], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6109, 0.1934, 0.5352, 0.1952], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5035, 0.5270, 0.1349, 0.5011], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1398, 0.6827, 0.7855, 0.1205], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4610, 0.4586, 0.6376, 0.4757], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8495, 0.4595, 0.3132, 0.7374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4301, 0.1302, 0.4527, 0.5942], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1540, 0.2118, 0.5255, 0.6996], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3018, 0.3589, 0.6152, 0.7836], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3610, 0.1184, 0.1855, 0.0774], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1169, 0.8136, 0.6225, 0.3197], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2963, 0.1583, 0.2578, 0.3697], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6998, 0.7375, 0.4982, 0.4331], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3403, 0.6822, 0.3606, 0.5026], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7622, 0.7451, 0.1434, 0.2355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2285, 0.4148, 0.6691, 0.7641], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1520, 0.2471, 0.6963, 0.7582], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3304, 0.2374, 0.4696, 0.8245], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1860, 0.3922, 0.2637, 0.4052], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4783, 0.4646, 0.4692, 0.6108], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2172, 0.7973, 0.3614, 0.4886], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2806, 0.6090, 0.4445, 0.5682], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5683, 0.5326, 0.6685, 0.6168], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3716, 0.2778, 0.6577, 0.4515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4826, 0.6907, 0.3129, 0.7296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4955, 0.3179, 0.6921, 0.7320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2055, 0.6701, 0.5864, 0.6158], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2706, 0.6762, 0.0991, 0.1609], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6189, 0.3640, 0.5875, 0.3409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5523, 0.4645, 0.7663, 0.3937], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6071, 0.2212, 0.8251, 0.6067], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7165, 0.6225, 0.8675, 0.7619], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0833, 0.3981, 0.4729, 0.4576], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6229, 0.4488, 0.1077, 0.3873], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3764, 0.1597, 0.1231, 0.4603], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6554, 0.4949, 0.7737, 0.3047], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8390, 0.4332, 0.4171, 0.7683], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1783, 0.5150, 0.1600, 0.1543], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2737, 0.5840, 0.7233, 0.4933], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5429, 0.5957, 0.4060, 0.4154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4002, 0.3912, 0.7364, 0.3642], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4891, 0.5775, 0.6327, 0.5874], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4658, 0.3459, 0.1476, 0.6036], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0932, 0.1117, 0.2941, 0.3114], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7606, 0.5431, 0.4429, 0.2711], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2270, 0.0614, 0.3614, 0.3859], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6622, 0.6427, 0.8676, 0.4682], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3458, 0.5235, 0.7229, 0.2580], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7652, 0.5414, 0.2945, 0.7477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4255, 0.6459, 0.2191, 0.5763], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3962, 0.6854, 0.7417, 0.1983], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2481, 0.7795, 0.3731, 0.6959], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4456, 0.7722, 0.7697, 0.6814], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7553, 0.3300, 0.3867, 0.6753], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3175, 0.5829, 0.4101, 0.4456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5571, 0.7210, 0.5704, 0.7073], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0703, 0.0753, 0.2318, 0.2074], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2951, 0.2946, 0.0615, 0.1237], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3846, 0.1402, 0.3796, 0.2035], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5647, 0.1776, 0.1760, 0.7284], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7423, 0.6186, 0.5320, 0.1870], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3070, 0.3632, 0.4530, 0.2637], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1153, 0.4940, 0.4288, 0.3072], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7269, 0.6507, 0.5682, 0.3425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7154, 0.3303, 0.1310, 0.1460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3351, 0.6883, 0.8430, 0.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1459, 0.4635, 0.3936, 0.1999], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5296, 0.1464, 0.1608, 0.1955], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7204, 0.5982, 0.1493, 0.5049], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4093, 0.7538, 0.6460, 0.1090], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6500, 0.2923, 0.2693, 0.7820], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7152, 0.1787, 0.7644, 0.3810], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1731, 0.2942, 0.4158, 0.3222], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7095, 0.2446, 0.4525, 0.1351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4115, 0.1055, 0.1166, 0.1835], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6344, 0.7198, 0.4348, 0.7697], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6799, 0.5849, 0.8472, 0.8793], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7505, 0.5750, 0.4212, 0.2385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4450, 0.2549, 0.6066, 0.7516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5807, 0.5688, 0.5747, 0.5197], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2103, 0.3401, 0.4535, 0.5969], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2168, 0.6357, 0.4505, 0.7204], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4469, 0.5792, 0.6201, 0.6330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1391, 0.2178, 0.5693, 0.1313], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6950, 0.2401, 0.5438, 0.4655], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2356, 0.2863, 0.4465, 0.2179], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6622, 0.1522, 0.6577, 0.1171], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1825, 0.3601, 0.6920, 0.5542], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6386, 0.7518, 0.1821, 0.1007], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2447, 0.0880, 0.3026, 0.5671], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1831, 0.2068, 0.1915, 0.3052], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2547, 0.7259, 0.3162, 0.2634], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6116, 0.8428, 0.5934, 0.5787], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7082, 0.4081, 0.7081, 0.5220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8113, 0.3830, 0.2804, 0.7878], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7122, 0.4920, 0.2259, 0.6275], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4001, 0.5794, 0.8370, 0.7324], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1541, 0.2294, 0.7818, 0.8347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0805, 0.3699, 0.4038, 0.5982], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8957, 0.7601, 0.8782, 0.6960], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5676, 0.1999, 0.4927, 0.2121], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7588, 0.5548, 0.8681, 0.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4512, 0.4310, 0.1678, 0.1126], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7541, 0.8515, 0.5032, 0.5307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5392, 0.2466, 0.7685, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5303, 0.2472, 0.1975, 0.6550], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3627, 0.5471, 0.5266, 0.3863], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3194, 0.1396, 0.6495, 0.7090], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7376, 0.7425, 0.2276, 0.1957], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3852, 0.4296, 0.2520, 0.3402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4833, 0.3770, 0.1907, 0.7557], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7548, 0.5803, 0.3267, 0.6355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5709, 0.1127, 0.5396, 0.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1903, 0.4410, 0.6401, 0.6425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6884, 0.8754, 0.8320, 0.4882], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7932, 0.3026, 0.2607, 0.3268], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4894, 0.1241, 0.4351, 0.2478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1466, 0.5286, 0.7309, 0.2744], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3681, 0.7021, 0.7565, 0.7138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8054, 0.1607, 0.7880, 0.2021], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3061, 0.6228, 0.2607, 0.4840], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6245, 0.8164, 0.8499, 0.4248], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1573, 0.4334, 0.7386, 0.2207], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2913, 0.4723, 0.1220, 0.5425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2843, 0.3753, 0.3208, 0.5242], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1411, 0.4074, 0.1453, 0.6704], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6714, 0.7224, 0.2198, 0.8092], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1062, 0.2552, 0.1844, 0.7469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1163, 0.2223, 0.5023, 0.6271], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7000, 0.3898, 0.4058, 0.5959], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8403, 0.7738, 0.8395, 0.6125], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5958, 0.3189, 0.1105, 0.6283], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1195, 0.2301, 0.5359, 0.6750], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7193, 0.6090, 0.4329, 0.7255], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6610, 0.5855, 0.1902, 0.3988], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8175, 0.4798, 0.3997, 0.4685], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6557, 0.8139, 0.4115, 0.5666], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6970, 0.2359, 0.4289, 0.3440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3890, 0.5173, 0.3132, 0.2828], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5264, 0.5663, 0.5404, 0.3137], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5138, 0.3861, 0.1434, 0.5247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2754, 0.2243, 0.6604, 0.4184], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2052, 0.0767, 0.6826, 0.3805], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3850, 0.8474, 0.6276, 0.4310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0810, 0.0726, 0.6182, 0.3858], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2518, 0.1632, 0.4179, 0.5460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2331, 0.2453, 0.5232, 0.4008], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2523, 0.2832, 0.2950, 0.8028], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4597, 0.5263, 0.3217, 0.7945], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3980, 0.6438, 0.0982, 0.4407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2012, 0.1158, 0.1740, 0.2967], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8153, 0.3390, 0.7540, 0.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6503, 0.7486, 0.8613, 0.6862], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6542, 0.8053, 0.4091, 0.2622], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6821, 0.4224, 0.5812, 0.6804], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3254, 0.4476, 0.7239, 0.8252], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8145, 0.3667, 0.2926, 0.5788], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4316, 0.3594, 0.4852, 0.6163], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2332, 0.6806, 0.1308, 0.3421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0929, 0.5789, 0.3296, 0.6797], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1341, 0.6346, 0.0952, 0.1223], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0934, 0.3050, 0.5824, 0.6467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3141, 0.1891, 0.3632, 0.1687], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4413, 0.8040, 0.4418, 0.7036], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1864, 0.6660, 0.1468, 0.1294], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1974, 0.5193, 0.4382, 0.3735], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3585, 0.3380, 0.7287, 0.6310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2773, 0.3034, 0.4171, 0.6298], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1935, 0.3409, 0.6213, 0.8014], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6989, 0.7637, 0.5117, 0.2724], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6832, 0.2143, 0.3674, 0.1456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3430, 0.2393, 0.2352, 0.6791], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4950, 0.4702, 0.5059, 0.2962], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6668, 0.3575, 0.4045, 0.2105], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5735, 0.1711, 0.6068, 0.6506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4184, 0.1216, 0.6758, 0.1676], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2595, 0.3030, 0.1960, 0.6027], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1801, 0.6579, 0.7249, 0.6232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3425, 0.8057, 0.5650, 0.4437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2728, 0.5723, 0.2772, 0.1062], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2791, 0.6651, 0.5885, 0.3112], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3630, 0.8443, 0.4940, 0.5093], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7324, 0.3792, 0.7600, 0.1373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4886, 0.0857, 0.3916, 0.0666], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5040, 0.7073, 0.4715, 0.3788], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7720, 0.1476, 0.2691, 0.3452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5483, 0.3578, 0.4899, 0.2595], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3269, 0.7133, 0.2622, 0.6565], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6792, 0.1352, 0.6700, 0.3523], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3831, 0.8444, 0.2282, 0.8196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3642, 0.7580, 0.3059, 0.4053], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7252, 0.4379, 0.3158, 0.2659], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4340, 0.4977, 0.4492, 0.6877], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5744, 0.4325, 0.3580, 0.8058], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4422, 0.7308, 0.1947, 0.5031], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3516, 0.2441, 0.7755, 0.1939], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0886, 0.4962, 0.2629, 0.0723], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1417, 0.5626, 0.1345, 0.4002], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6709, 0.8482, 0.7574, 0.7686], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8055, 0.6742, 0.3792, 0.2636], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8276, 0.5449, 0.1950, 0.7642], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2485, 0.2932, 0.7735, 0.0978], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6857, 0.2555, 0.4192, 0.1677], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4426, 0.7264, 0.8619, 0.5789], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3023, 0.1466, 0.0470, 0.4052], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8027, 0.2907, 0.1740, 0.3922], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1955, 0.0741, 0.3713, 0.2878], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4499, 0.5311, 0.8343, 0.3217], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1579, 0.1139, 0.0593, 0.5383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6195, 0.4726, 0.3766, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5354, 0.5575, 0.4960, 0.6218], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8012, 0.4683, 0.5724, 0.1138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8887, 0.5537, 0.8500, 0.7329], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7707, 0.4660, 0.2212, 0.5650], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1150, 0.3628, 0.2831, 0.6406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5831, 0.1092, 0.2792, 0.3731], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0931, 0.5546, 0.1179, 0.6502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3482, 0.4732, 0.4773, 0.2487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7754, 0.4561, 0.7034, 0.3064], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3351, 0.3055, 0.4247, 0.5278], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1071, 0.1358, 0.6627, 0.4058], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4361, 0.7474, 0.1413, 0.6644], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8214, 0.2878, 0.7833, 0.4072], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5460, 0.6434, 0.2091, 0.3587], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4296, 0.7882, 0.7888, 0.6794], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6145, 0.7029, 0.7933, 0.4676], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4612, 0.3795, 0.1982, 0.1185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8012, 0.1540, 0.3011, 0.0834], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2550, 0.4366, 0.0563, 0.1315], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3108, 0.7772, 0.5688, 0.6127], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7556, 0.4897, 0.7391, 0.4893], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2496, 0.7849, 0.3424, 0.5749], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5904, 0.5296, 0.5995, 0.2823], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6292, 0.3780, 0.5929, 0.7039], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2079, 0.1795, 0.6055, 0.2191], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3519, 0.6413, 0.7310, 0.7409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3476, 0.1054, 0.4363, 0.5626], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6468, 0.8364, 0.1955, 0.7806], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6989, 0.8250, 0.5344, 0.2066], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2735, 0.4065, 0.3503, 0.2296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3850, 0.2684, 0.7056, 0.7393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2624, 0.7680, 0.6793, 0.6409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2017, 0.7485, 0.5395, 0.0987], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6627, 0.6494, 0.3153, 0.3544], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2676, 0.3520, 0.3117, 0.2370], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8107, 0.2599, 0.1838, 0.8045], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4163, 0.1647, 0.6842, 0.2100], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7608, 0.7317, 0.1429, 0.8176], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1627, 0.6067, 0.3617, 0.3436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6174, 0.3677, 0.4083, 0.5173], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2424, 0.5660, 0.8304, 0.4968], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4361, 0.2856, 0.2281, 0.6853], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8099, 0.7199, 0.6331, 0.8911], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7252, 0.3428, 0.4740, 0.7234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6373, 0.5181, 0.4867, 0.8125], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6434, 0.2762, 0.4759, 0.4954], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6429, 0.4721, 0.6903, 0.4341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5102, 0.3748, 0.4303, 0.5139], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6220, 0.3762, 0.4383, 0.1318], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1000, 0.2205, 0.3994, 0.6934], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1391, 0.2930, 0.3639, 0.4512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2898, 0.8621, 0.6719, 0.7674], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7080, 0.1650, 0.0756, 0.3311], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2689, 0.1500, 0.2667, 0.4056], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8207, 0.7776, 0.4970, 0.7975], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4014, 0.1605, 0.5712, 0.6004], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0699, 0.4572, 0.1435, 0.4558], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5696, 0.1769, 0.6411, 0.3428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6015, 0.8514, 0.7449, 0.3205], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3178, 0.7089, 0.8172, 0.3145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4116, 0.7929, 0.3615, 0.2080], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8566, 0.8889, 0.8060, 0.6274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6111, 0.0954, 0.3092, 0.3636], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1902, 0.3703, 0.7818, 0.4349], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3262, 0.6132, 0.8054, 0.4766], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7351, 0.3526, 0.8220, 0.6746], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6012, 0.5812, 0.8300, 0.3050], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2974, 0.1835, 0.1830, 0.6345], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6565, 0.8052, 0.8453, 0.6363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1015, 0.4060, 0.7225, 0.0988], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1455, 0.2104, 0.7263, 0.5165], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0594, 0.3417, 0.1519, 0.2842], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7967, 0.7717, 0.6051, 0.6757], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1261, 0.1605, 0.5109, 0.3385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4640, 0.5943, 0.3508, 0.2536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2139, 0.6295, 0.5058, 0.1473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7661, 0.0895, 0.2265, 0.0912], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2165, 0.2094, 0.1378, 0.6966], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3052, 0.2974, 0.2422, 0.2408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2693, 0.2770, 0.4750, 0.2649], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4778, 0.4190, 0.6252, 0.3676], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6230, 0.8416, 0.3640, 0.7772], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1314, 0.7594, 0.6489, 0.3644], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5110, 0.3152, 0.6518, 0.2167], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4818, 0.3373, 0.5679, 0.5961], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0891, 0.4430, 0.1321, 0.4979], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8197, 0.8737, 0.3085, 0.8168], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8317, 0.5951, 0.4964, 0.8763], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2547, 0.5796, 0.3002, 0.3184], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6180, 0.5557, 0.4977, 0.3714], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5488, 0.1122, 0.0774, 0.7374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4101, 0.6479, 0.4705, 0.4117], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6507, 0.4727, 0.2808, 0.7174], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2988, 0.6893, 0.7885, 0.6773], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4086, 0.3945, 0.6746, 0.3869], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3752, 0.6534, 0.7725, 0.5922], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5095, 0.5763, 0.4580, 0.2494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7449, 0.7140, 0.4923, 0.6307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7887, 0.5859, 0.2310, 0.4921], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3307, 0.2751, 0.6240, 0.1167], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4362, 0.0930, 0.6745, 0.5668], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4863, 0.2124, 0.5585, 0.5535], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8036, 0.5508, 0.2887, 0.7538], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3712, 0.3323, 0.3843, 0.2816], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6686, 0.1686, 0.4638, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4605, 0.4916, 0.2983, 0.0884], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1970, 0.3826, 0.4726, 0.1576], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7970, 0.7343, 0.4695, 0.6283], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8111, 0.3825, 0.6029, 0.7525], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5121, 0.4510, 0.5613, 0.2942], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4637, 0.5350, 0.6808, 0.8295], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7571, 0.4866, 0.1388, 0.7887], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4219, 0.1938, 0.3882, 0.2950], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6696, 0.3794, 0.5214, 0.3787], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6144, 0.3531, 0.4492, 0.3041], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2219, 0.0568, 0.3439, 0.0572], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0637, 0.1028, 0.6640, 0.2741], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4815, 0.3542, 0.1450, 0.5395], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4070, 0.1048, 0.7366, 0.1418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6084, 0.7435, 0.2585, 0.7238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2877, 0.3028, 0.7022, 0.4764], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4942, 0.3401, 0.5619, 0.2598], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5724, 0.1451, 0.4842, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8346, 0.4542, 0.7446, 0.1769], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0855, 0.4187, 0.5585, 0.2675], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3634, 0.1938, 0.4009, 0.2530], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1109, 0.0746, 0.2037, 0.3898], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4768, 0.7922, 0.0958, 0.3408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2896, 0.4323, 0.7823, 0.7332], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6215, 0.7011, 0.7640, 0.2307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2384, 0.3034, 0.7981, 0.2413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5719, 0.0906, 0.6066, 0.1864], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6138, 0.8437, 0.5363, 0.3185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4090, 0.5513, 0.5270, 0.7065], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3304, 0.6791, 0.2622, 0.5064], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7496, 0.7028, 0.6522, 0.2737], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7463, 0.5684, 0.2566, 0.2594], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3475, 0.8337, 0.4058, 0.7493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3314, 0.7623, 0.5076, 0.4953], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6213, 0.4303, 0.3068, 0.3961], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4659, 0.1633, 0.4134, 0.7414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8068, 0.4216, 0.5693, 0.4274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1345, 0.5363, 0.6209, 0.5615], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0565, 0.1732, 0.0583, 0.3354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4827, 0.4038, 0.6137, 0.1378], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7670, 0.6704, 0.8125, 0.1504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5390, 0.3828, 0.1446, 0.3352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5040, 0.4313, 0.5446, 0.6809], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3385, 0.1989, 0.6453, 0.4992], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4988, 0.4318, 0.3396, 0.4487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1151, 0.1528, 0.1075, 0.6307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8319, 0.7742, 0.8790, 0.3250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5062, 0.4755, 0.5521, 0.1850], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6171, 0.5076, 0.0910, 0.3164], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3298, 0.8196, 0.3101, 0.4910], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0462, 0.4478, 0.0414, 0.2252], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6155, 0.7397, 0.3937, 0.7798], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6594, 0.6048, 0.2029, 0.1529], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4581, 0.8687, 0.7122, 0.5208], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6837, 0.8442, 0.4704, 0.4164], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4425, 0.1596, 0.2646, 0.1044], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6256, 0.8499, 0.5077, 0.4134], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1578, 0.4027, 0.1539, 0.7010], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2648, 0.3426, 0.2433, 0.3006], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5777, 0.7755, 0.1305, 0.4896], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2691, 0.7112, 0.7733, 0.1561], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3014, 0.8026, 0.6363, 0.8265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7717, 0.0791, 0.3410, 0.2894], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6833, 0.8149, 0.4925, 0.4548], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5292, 0.2144, 0.6706, 0.2139], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1357, 0.0495, 0.0769, 0.1084], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3068, 0.6554, 0.5846, 0.6552], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1243, 0.7522, 0.2884, 0.8266], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4234, 0.1164, 0.1816, 0.5998], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4289, 0.0477, 0.2598, 0.1091], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5164, 0.7539, 0.5018, 0.3030], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3163, 0.0977, 0.2141, 0.5093], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5349, 0.7485, 0.5022, 0.2436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1863, 0.2909, 0.0813, 0.0599], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3493, 0.7179, 0.7916, 0.1119], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8103, 0.2326, 0.1984, 0.2359], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3964, 0.6712, 0.2387, 0.6710], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1216, 0.4999, 0.4195, 0.0944], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4892, 0.8364, 0.6419, 0.6393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5360, 0.7836, 0.6067, 0.1537], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1497, 0.6911, 0.4188, 0.2496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7081, 0.5456, 0.5813, 0.5737], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8048, 0.3165, 0.2180, 0.2792], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2635, 0.3283, 0.1097, 0.0982], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5136, 0.7165, 0.5568, 0.2920], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7517, 0.2186, 0.7288, 0.6394], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1018, 0.6933, 0.1576, 0.3165], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4449, 0.7396, 0.6875, 0.5501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4322, 0.2285, 0.7859, 0.6860], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2395, 0.7923, 0.2217, 0.8234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3190, 0.8297, 0.6115, 0.4343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7111, 0.8237, 0.2635, 0.1276], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1056, 0.7107, 0.2363, 0.1147], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2500, 0.8802, 0.8637, 0.7668], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2362, 0.6263, 0.7860, 0.2163], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1245, 0.2816, 0.5527, 0.5614], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6575, 0.1631, 0.2085, 0.5314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4855, 0.6225, 0.6286, 0.8275], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6055, 0.1843, 0.8021, 0.7247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4057, 0.1581, 0.4070, 0.6850], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6162, 0.2055, 0.3419, 0.6276], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5720, 0.5558, 0.7917, 0.4203], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6727, 0.1702, 0.2757, 0.7806], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0845, 0.4615, 0.1042, 0.2911], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2682, 0.8167, 0.3547, 0.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2471, 0.0607, 0.2019, 0.3836], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7465, 0.7558, 0.3636, 0.5465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4630, 0.5428, 0.4166, 0.2091], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4712, 0.6918, 0.3630, 0.2073], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2211, 0.7435, 0.7750, 0.1693], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3257, 0.2614, 0.5151, 0.5696], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3255, 0.3731, 0.3538, 0.5682], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4477, 0.2935, 0.4357, 0.4751], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5288, 0.4929, 0.5881, 0.3652], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2499, 0.8108, 0.6200, 0.4201], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4638, 0.5703, 0.3454, 0.7420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4469, 0.6842, 0.3657, 0.7750], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6453, 0.8071, 0.7668, 0.2090], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6090, 0.6226, 0.2492, 0.4200], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1193, 0.2761, 0.2681, 0.7790], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8216, 0.8508, 0.5100, 0.6257], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8029, 0.1113, 0.5494, 0.2932], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0869, 0.1746, 0.6125, 0.4660], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7209, 0.6695, 0.8592, 0.1796], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5223, 0.2711, 0.8201, 0.4763], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0783, 0.4950, 0.4187, 0.4129], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2072, 0.7294, 0.5188, 0.2263], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5835, 0.4741, 0.1916, 0.1007], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1318, 0.1107, 0.2253, 0.3788], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4742, 0.2230, 0.7235, 0.5064], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6255, 0.8024, 0.5798, 0.5951], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7721, 0.6155, 0.3040, 0.4337], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2736, 0.4428, 0.3321, 0.6390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6687, 0.3595, 0.3253, 0.5190], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4135, 0.3685, 0.5254, 0.6279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7424, 0.6977, 0.7667, 0.3374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5960, 0.5791, 0.1603, 0.3152], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1541, 0.3356, 0.7229, 0.1470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7484, 0.6473, 0.5490, 0.7938], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4422, 0.5681, 0.5900, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6665, 0.1980, 0.5790, 0.6454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4375, 0.5831, 0.6595, 0.1506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5371, 0.8098, 0.6596, 0.1805], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1750, 0.1020, 0.8067, 0.3442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4248, 0.7484, 0.0762, 0.1244], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3023, 0.4634, 0.6531, 0.5577], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6206, 0.8541, 0.5417, 0.4913], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8584, 0.4387, 0.4932, 0.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3576, 0.2022, 0.0710, 0.1540], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3883, 0.8301, 0.8090, 0.5482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0653, 0.2120, 0.5237, 0.3894], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3649, 0.1972, 0.7282, 0.6480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1165, 0.3427, 0.5021, 0.4940], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8198, 0.2121, 0.7195, 0.3979], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7891, 0.7340, 0.7776, 0.4734], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5564, 0.7386, 0.5074, 0.5711], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3441, 0.3717, 0.4053, 0.3515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1625, 0.6620, 0.1158, 0.5763], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7078, 0.7652, 0.8447, 0.3823], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6850, 0.0883, 0.1883, 0.6365], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1688, 0.4085, 0.6041, 0.1993], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6688, 0.0947, 0.4695, 0.5506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7653, 0.4209, 0.5720, 0.3552], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4142, 0.5441, 0.5275, 0.3265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4948, 0.5438, 0.4763, 0.3210], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1775, 0.3111, 0.8171, 0.3896], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6502, 0.3358, 0.0744, 0.1959], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5828, 0.6310, 0.3359, 0.7054], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2788, 0.4166, 0.7837, 0.2285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6006, 0.5046, 0.1935, 0.2063], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2655, 0.4604, 0.8521, 0.7685], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5945, 0.2686, 0.1679, 0.7347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3798, 0.4072, 0.6344, 0.5403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3938, 0.1415, 0.2095, 0.2814], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7638, 0.7225, 0.7537, 0.1504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5965, 0.7187, 0.8473, 0.5755], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3055, 0.7957, 0.6104, 0.5664], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8284, 0.5543, 0.7555, 0.8698], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8090, 0.6488, 0.7221, 0.6144], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5174, 0.3694, 0.0893, 0.5026], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4566, 0.8498, 0.3830, 0.8017], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7793, 0.1930, 0.5469, 0.6494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7745, 0.2472, 0.1866, 0.5367], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3043, 0.5493, 0.5435, 0.6782], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4743, 0.6554, 0.8157, 0.5427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7941, 0.6151, 0.8536, 0.5413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7994, 0.4197, 0.6220, 0.4253], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4568, 0.1844, 0.0860, 0.2694], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5984, 0.5430, 0.3965, 0.7013], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1045, 0.2086, 0.2063, 0.0829], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1845, 0.3922, 0.4260, 0.4755], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6943, 0.2094, 0.1689, 0.7153], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6328, 0.4930, 0.7510, 0.3527], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8681, 0.8585, 0.9097, 0.8667], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1273, 0.1483, 0.7303, 0.3297], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7616, 0.2698, 0.7445, 0.8603], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6463, 0.2889, 0.6419, 0.1839], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3165, 0.8281, 0.4756, 0.5961], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4908, 0.1419, 0.5326, 0.5078], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4920, 0.1565, 0.2344, 0.5733], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5608, 0.5254, 0.3133, 0.7864], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8073, 0.7257, 0.1630, 0.1141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5907, 0.2570, 0.0914, 0.6791], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5516, 0.3225, 0.4196, 0.4379], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5446, 0.7551, 0.4239, 0.4745], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1124, 0.5177, 0.7183, 0.7026], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0931, 0.0576, 0.4457, 0.5017], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8334, 0.8895, 0.8025, 0.7288], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6976, 0.7498, 0.7101, 0.2951], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0580, 0.5966, 0.0929, 0.0609], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4685, 0.5616, 0.4435, 0.7655], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1921, 0.7733, 0.4629, 0.3980], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6376, 0.4759, 0.8348, 0.6373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6981, 0.0874, 0.0616, 0.2689], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4206, 0.6885, 0.7112, 0.7583], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2350, 0.2661, 0.3794, 0.2878], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4212, 0.4317, 0.3894, 0.3734], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8075, 0.5359, 0.4809, 0.8021], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1953, 0.3973, 0.6053, 0.2398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8601, 0.6748, 0.3786, 0.6423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2103, 0.7888, 0.6026, 0.1256], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7763, 0.6596, 0.6187, 0.3828], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5847, 0.5246, 0.5627, 0.4123], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1323, 0.5581, 0.6975, 0.7467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2403, 0.7647, 0.3112, 0.2016], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4760, 0.1481, 0.1158, 0.2009], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8325, 0.6673, 0.5898, 0.1972], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2195, 0.5517, 0.3181, 0.2249], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8377, 0.2748, 0.6282, 0.5246], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6287, 0.1815, 0.3836, 0.4823], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4919, 0.2375, 0.1843, 0.1945], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2934, 0.2305, 0.5791, 0.0775], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7318, 0.8135, 0.4102, 0.6599], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8502, 0.7227, 0.5919, 0.1910], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4193, 0.6720, 0.8658, 0.6814], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2861, 0.3921, 0.0894, 0.4516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6875, 0.1199, 0.4900, 0.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1586, 0.6691, 0.6321, 0.6479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2842, 0.3981, 0.1934, 0.6449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3236, 0.1641, 0.4062, 0.4644], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4972, 0.2278, 0.3568, 0.6749], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4866, 0.5126, 0.2796, 0.4050], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0625, 0.3917, 0.4918, 0.1925], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5697, 0.1543, 0.2550, 0.7452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2533, 0.4398, 0.4096, 0.3281], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1675, 0.2482, 0.8081, 0.5619], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6039, 0.4773, 0.2290, 0.6909], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5168, 0.1513, 0.7271, 0.6320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8565, 0.8070, 0.2088, 0.8535], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1081, 0.6536, 0.1663, 0.6824], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6229, 0.6893, 0.7598, 0.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6260, 0.1872, 0.7810, 0.2640], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3815, 0.5393, 0.2570, 0.0959], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1174, 0.6378, 0.7668, 0.1589], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3005, 0.4341, 0.3804, 0.3341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4453, 0.4729, 0.2590, 0.6406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5462, 0.7574, 0.5459, 0.4129], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6866, 0.2570, 0.2216, 0.4747], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2134, 0.3284, 0.7008, 0.6641], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7578, 0.6092, 0.8139, 0.5055], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6977, 0.6313, 0.4860, 0.4700], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6271, 0.1937, 0.3038, 0.4255], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1075, 0.5059, 0.3295, 0.5140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1854, 0.3689, 0.1700, 0.1418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1684, 0.7739, 0.8239, 0.2208], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1212, 0.5443, 0.4792, 0.4757], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5552, 0.7191, 0.6005, 0.7287], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4552, 0.1216, 0.1796, 0.5524], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6265, 0.8227, 0.5794, 0.6182], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7668, 0.3698, 0.7879, 0.7103], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8374, 0.2286, 0.6524, 0.5741], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8549, 0.7660, 0.3252, 0.5639], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7289, 0.7248, 0.6527, 0.8095], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8379, 0.4782, 0.7586, 0.5431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6589, 0.7978, 0.6629, 0.3356], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6281, 0.1629, 0.0957, 0.4757], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4194, 0.5459, 0.1521, 0.7045], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4116, 0.5556, 0.7640, 0.8335], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3865, 0.7305, 0.6138, 0.6812], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7730, 0.3011, 0.4392, 0.5654], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7091, 0.5284, 0.7517, 0.4691], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2593, 0.3419, 0.2676, 0.8114], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6630, 0.1044, 0.3643, 0.7117], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7979, 0.1470, 0.4341, 0.1802], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6989, 0.7430, 0.8197, 0.4190], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1569, 0.6883, 0.6378, 0.1380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3015, 0.6924, 0.3559, 0.3935], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5767, 0.5653, 0.8005, 0.6239], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5005, 0.3269, 0.6029, 0.4134], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2756, 0.6319, 0.7629, 0.3730], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8350, 0.6412, 0.7746, 0.4362], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3199, 0.1952, 0.7863, 0.5986], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5121, 0.4579, 0.2574, 0.3306], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5012, 0.1217, 0.6602, 0.4040], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6464, 0.4051, 0.3468, 0.7494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3961, 0.2456, 0.2579, 0.6601], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3035, 0.7220, 0.6859, 0.0985], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7128, 0.1040, 0.4871, 0.5689], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1801, 0.3652, 0.3245, 0.2960], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3922, 0.3684, 0.1441, 0.7632], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2713, 0.7090, 0.2959, 0.8392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6254, 0.6738, 0.5724, 0.5135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3042, 0.2728, 0.0803, 0.1625], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4483, 0.2228, 0.6980, 0.2112], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2595, 0.8134, 0.4194, 0.2861], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1721, 0.1494, 0.6329, 0.4906], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1591, 0.8048, 0.6584, 0.5364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2608, 0.2986, 0.2505, 0.4617], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2948, 0.6785, 0.2158, 0.3706], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0982, 0.1470, 0.7559, 0.0910], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8065, 0.0986, 0.7150, 0.1056], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4161, 0.1723, 0.1536, 0.5104], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3830, 0.1969, 0.2393, 0.7636], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3933, 0.4042, 0.5177, 0.6517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6578, 0.1080, 0.6748, 0.1269], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7462, 0.4556, 0.2657, 0.5765], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2904, 0.7019, 0.4207, 0.1930], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3987, 0.1005, 0.7484, 0.3066], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1346, 0.2940, 0.1081, 0.7773], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2335, 0.6655, 0.0938, 0.3936], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6757, 0.1736, 0.6305, 0.3997], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3929, 0.3770, 0.2984, 0.6926], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6264, 0.6336, 0.1096, 0.3128], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2570, 0.7665, 0.3912, 0.2760], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1763, 0.0957, 0.4439, 0.1823], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8080, 0.1821, 0.6129, 0.4753], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6856, 0.1109, 0.7670, 0.3740], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8665, 0.6786, 0.7925, 0.3675], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3865, 0.4452, 0.6699, 0.3264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6117, 0.7744, 0.8622, 0.7135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4704, 0.7103, 0.5407, 0.3727], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5737, 0.2216, 0.6028, 0.6777], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7871, 0.6042, 0.5483, 0.8347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4646, 0.4672, 0.3712, 0.5504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4108, 0.0896, 0.1624, 0.1481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2354, 0.6740, 0.1388, 0.4789], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5781, 0.1945, 0.5537, 0.1163], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7480, 0.7307, 0.4280, 0.1539], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3629, 0.4308, 0.2057, 0.3878], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5573, 0.5066, 0.8090, 0.6443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8251, 0.7117, 0.7270, 0.4740], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7659, 0.1426, 0.4099, 0.4913], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6394, 0.2863, 0.4718, 0.1241], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3304, 0.7427, 0.0728, 0.0837], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5389, 0.4401, 0.6074, 0.1260], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3009, 0.2633, 0.6680, 0.4472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0900, 0.0640, 0.3469, 0.0574], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5042, 0.7374, 0.7103, 0.6122], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3118, 0.2003, 0.0763, 0.6080], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8531, 0.3385, 0.6460, 0.6715], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5530, 0.1536, 0.5947, 0.4235], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8475, 0.4991, 0.7193, 0.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2269, 0.0566, 0.1160, 0.4995], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2162, 0.1997, 0.0717, 0.4293], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4773, 0.7938, 0.1854, 0.4333], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7850, 0.7857, 0.3823, 0.5570], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6083, 0.8151, 0.2863, 0.7298], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8065, 0.8501, 0.6162, 0.3233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7435, 0.1585, 0.7136, 0.1128], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6946, 0.3064, 0.6458, 0.5220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7998, 0.2478, 0.5856, 0.0896], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4645, 0.2391, 0.6774, 0.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8367, 0.5376, 0.3289, 0.3569], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6527, 0.3323, 0.3257, 0.1230], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6280, 0.3786, 0.7784, 0.5077], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0278, 0.0662, 0.0420, 0.0891], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3843, 0.5698, 0.1975, 0.7563], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4734, 0.6736, 0.2605, 0.4157], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5277, 0.0821, 0.5216, 0.4459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2888, 0.2680, 0.2975, 0.1272], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3486, 0.2762, 0.4807, 0.5754], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2055, 0.6808, 0.3594, 0.2652], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5960, 0.1688, 0.7500, 0.0961], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6516, 0.7920, 0.5653, 0.4538], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5489, 0.4176, 0.5040, 0.5517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2642, 0.7069, 0.6843, 0.5687], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3429, 0.5067, 0.6862, 0.7565], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3805, 0.6431, 0.5098, 0.5725], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2005, 0.5193, 0.6765, 0.2461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7416, 0.8467, 0.5901, 0.3517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4671, 0.6076, 0.6114, 0.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1569, 0.6864, 0.2857, 0.3843], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5319, 0.0833, 0.3121, 0.5995], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3237, 0.4461, 0.2212, 0.2435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5271, 0.8638, 0.7059, 0.6086], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1980, 0.4921, 0.5463, 0.5589], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4752, 0.7723, 0.6686, 0.1801], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4237, 0.6805, 0.8202, 0.4722], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6773, 0.5480, 0.0934, 0.5150], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2662, 0.7219, 0.1679, 0.1602], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1600, 0.7379, 0.4766, 0.6357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6105, 0.2988, 0.4995, 0.5635], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5128, 0.6480, 0.5765, 0.7021], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1496, 0.3982, 0.1052, 0.1131], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3727, 0.0847, 0.6768, 0.0710], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8114, 0.1437, 0.1247, 0.7092], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.7902, 0.2260, 0.4067, 0.7438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2674, 0.5701, 0.7172, 0.6966], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3118, 0.6238, 0.8613, 0.6242], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3924, 0.4595, 0.8193, 0.4309], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3630, 0.3592, 0.7721, 0.3203], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5658, 0.2714, 0.1496, 0.7910], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5881, 0.5648, 0.5965, 0.2196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3267, 0.6231, 0.3784, 0.4970], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4865, 0.2819, 0.7902, 0.4866], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6042, 0.5489, 0.4148, 0.1925], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1157, 0.6817, 0.6397, 0.7762], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5531, 0.6984, 0.6616, 0.6654], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3565, 0.3345, 0.6874, 0.5304], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0660, 0.1287, 0.3259, 0.6799], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0478, 0.3875, 0.1180, 0.3089], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8493, 0.6928, 0.5801, 0.5624], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.5592, 0.2283, 0.3244, 0.3548], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3813, 0.3393, 0.6739, 0.3188], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.1310, 0.3494, 0.3088, 0.7675], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3496, 0.3431, 0.6965, 0.2361], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.8090, 0.2659, 0.7725, 0.6723], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2063, 0.5576, 0.2782, 0.7187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0485, 0.2096, 0.3854, 0.2512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6398, 0.2118, 0.1658, 0.6134], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.6558, 0.4939, 0.7941, 0.3374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2601, 0.2062, 0.2512, 0.0743], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.2980, 0.8017, 0.8435, 0.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.0648, 0.4898, 0.0850, 0.1536], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.3887, 0.1437, 0.7623, 0.2287], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Placebo\n",
    "\n",
    "l2_norms = []\n",
    "for _ in range(10):\n",
    "  index = np.random.randint(1, N, size=100)\n",
    "\n",
    "  synthetic_x = []\n",
    "  for i in index:\n",
    "    model = SC(N, P, T)\n",
    "    optimizer = torch.optim.SGD([model.h, model.L, model.delta, model.gamma],\n",
    "                              lr=0.01)\n",
    "    mask = torch.ones(N, T)\n",
    "    mask[i, :] = 0\n",
    "\n",
    "    Y_t_local = torch.multiply(Y_t, mask)\n",
    "\n",
    "    for _ in range(3000):\n",
    "      optimizer.zero_grad()\n",
    "      loss = model.forward(X_t, Y_t_local)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    print(model.L[i, :])\n",
    "    synthetic_x.append(model.L[i, :].detach().numpy())\n",
    "    \n",
    "  err = (Y.iloc[index] - np.array(synthetic_x)).to_numpy()\n",
    "  l2_norms.append(np.linalg.norm(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[155.2553644196368,\n",
       " 157.12346017896985,\n",
       " 176.9487826724381,\n",
       " 134.21047951931033,\n",
       " 94.38464615699,\n",
       " 1845.8810183209728,\n",
       " 1849.6665621730567,\n",
       " 188.97714814154372,\n",
       " 115.76309132686796,\n",
       " 203.28503841855994]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492.14955913283467"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(l2_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214.56684967632714"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.var(l2_norms)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
